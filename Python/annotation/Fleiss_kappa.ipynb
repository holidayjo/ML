{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13364026",
   "metadata": {},
   "source": [
    "## Selecting images and annotation.\n",
    "\n",
    "50/100/50\n",
    "\n",
    "U / D / P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2511526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6378/6378 [00:08<00:00, 767.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total objects found: 12925\n",
      "Pool size -> Asc: 4380, Desc: 4236, Pass: 4309\n",
      "Final Survey Size: 200 images\n",
      "Generating images and Excel sheet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 249.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SUCCESS]\n",
      "Generated 200 images.\n",
      "Ascending: 50\n",
      "Descending: 100\n",
      "Passing: 50\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import xlsxwriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "DATASET_DIR = \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/Euljiro_/all_for_FleissKappa\"\n",
    "IMAGE_DIR = os.path.join(DATASET_DIR, \"images\")\n",
    "LABEL_DIR = os.path.join(DATASET_DIR, \"labels\")\n",
    "OUTPUT_DIR = \"./survey_material\"\n",
    "EXCEL_FILENAME = \"Annotator_Task_Form.xlsx\"\n",
    "\n",
    "# TARGET DISTRIBUTION (50 / 100 / 50)\n",
    "TARGET_COUNTS = {\n",
    "    0: 50,   # Ascending\n",
    "    1: 100,  # Descending (Main focus)\n",
    "    2: 50    # Passing\n",
    "}\n",
    "# =================================================\n",
    "\n",
    "def parse_yolo_line(line, img_width, img_height):\n",
    "    parts = line.strip().split()\n",
    "    class_id = int(parts[0])\n",
    "    x_center = float(parts[1]) * img_width\n",
    "    y_center = float(parts[2]) * img_height\n",
    "    width = float(parts[3]) * img_width\n",
    "    height = float(parts[4]) * img_height\n",
    "    \n",
    "    x1 = int(x_center - width / 2)\n",
    "    y1 = int(y_center - height / 2)\n",
    "    x2 = int(x_center + width / 2)\n",
    "    y2 = int(y_center + height / 2)\n",
    "    \n",
    "    return class_id, x1, y1, x2, y2\n",
    "\n",
    "def main():\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "    # --- 1. Collect All Objects ---\n",
    "    print(\"Scanning dataset...\")\n",
    "    all_objects = []\n",
    "    \n",
    "    image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    for img_file in tqdm(image_files):\n",
    "        txt_file = img_file.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "        txt_path = os.path.join(LABEL_DIR, txt_file)\n",
    "        img_path = os.path.join(IMAGE_DIR, img_file)\n",
    "        \n",
    "        if not os.path.exists(txt_path): continue\n",
    "            \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                cls, x1, y1, x2, y2 = parse_yolo_line(line, w, h)\n",
    "                # Only collect classes 0, 1, 2 (Ignore others if any)\n",
    "                if cls in TARGET_COUNTS:\n",
    "                    all_objects.append({\n",
    "                        'img_name': img_file,\n",
    "                        'img_path': img_path,\n",
    "                        'class_id': cls,\n",
    "                        'box': (x1, y1, x2, y2)\n",
    "                    })\n",
    "\n",
    "    # --- 2. Stratified Sampling (50 / 100 / 50) ---\n",
    "    print(f\"Total objects found: {len(all_objects)}\")\n",
    "    \n",
    "    # Separate lists by class\n",
    "    objs_0 = [x for x in all_objects if x['class_id'] == 0]\n",
    "    objs_1 = [x for x in all_objects if x['class_id'] == 1]\n",
    "    objs_2 = [x for x in all_objects if x['class_id'] == 2]\n",
    "    \n",
    "    print(f\"Pool size -> Asc: {len(objs_0)}, Desc: {len(objs_1)}, Pass: {len(objs_2)}\")\n",
    "    \n",
    "    selected_objects = []\n",
    "    \n",
    "    # Sample exact amounts (using min to avoid errors if pool is too small)\n",
    "    selected_objects.extend(random.sample(objs_0, min(len(objs_0), TARGET_COUNTS[0])))\n",
    "    selected_objects.extend(random.sample(objs_1, min(len(objs_1), TARGET_COUNTS[1])))\n",
    "    selected_objects.extend(random.sample(objs_2, min(len(objs_2), TARGET_COUNTS[2])))\n",
    "    \n",
    "    # Shuffle the final list so annotators don't see all \"Ascending\" first\n",
    "    random.shuffle(selected_objects)\n",
    "    \n",
    "    print(f\"Final Survey Size: {len(selected_objects)} images\")\n",
    "    \n",
    "    # --- 3. Generate Images & Excel ---\n",
    "    print(\"Generating images and Excel sheet...\")\n",
    "    excel_data = []\n",
    "    ground_truth_data = []\n",
    "    \n",
    "    for i, obj in enumerate(tqdm(selected_objects)):\n",
    "        img = cv2.imread(obj['img_path'])\n",
    "        x1, y1, x2, y2 = obj['box']\n",
    "        \n",
    "        # Draw Blue Box\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        \n",
    "        out_name = f\"survey_{i:03d}.jpg\"\n",
    "        cv2.imwrite(os.path.join(OUTPUT_DIR, out_name), img)\n",
    "        \n",
    "        excel_data.append({\n",
    "            'Image_ID': out_name,\n",
    "            'Your_Choice': '' \n",
    "        })\n",
    "        \n",
    "        ground_truth_data.append({\n",
    "            'Image_ID': out_name,\n",
    "            'GT_Label': obj['class_id']\n",
    "        })\n",
    "\n",
    "    # --- 4. Create Excel with Dropdown (Fixed) ---\n",
    "    workbook = xlsxwriter.Workbook(EXCEL_FILENAME)\n",
    "    worksheet = workbook.add_worksheet(\"AnnotationTask\")\n",
    "    \n",
    "    header_fmt = workbook.add_format({'bold': True, 'bg_color': '#D3D3D3', 'border': 1})\n",
    "    \n",
    "    worksheet.write('A1', 'Image File Name', header_fmt)\n",
    "    worksheet.write('B1', 'Select Action (Click Cell)', header_fmt)\n",
    "    worksheet.write('C1', 'Notes (Optional)', header_fmt)\n",
    "    \n",
    "    worksheet.set_column('A:A', 20)\n",
    "    worksheet.set_column('B:B', 25)\n",
    "    worksheet.set_column('C:C', 30)\n",
    "    \n",
    "    for row_idx, item in enumerate(excel_data):\n",
    "        worksheet.write(row_idx + 1, 0, item['Image_ID'])\n",
    "        \n",
    "        # *** FIX: Added correct start_row, start_col, end_row, end_col ***\n",
    "        worksheet.data_validation(row_idx + 1, 1, row_idx + 1, 1, {\n",
    "            'validate': 'list',\n",
    "            'source': ['0: Ascending', '1: Descending', '2: Passing']\n",
    "        })\n",
    "\n",
    "    workbook.close()\n",
    "    \n",
    "    # Save Key\n",
    "    pd.DataFrame(ground_truth_data).to_excel(\"Answer_Key_DO_NOT_SEND.xlsx\", index=False)\n",
    "    \n",
    "    print(\"\\n[SUCCESS]\")\n",
    "    print(f\"Generated {len(selected_objects)} images.\")\n",
    "    print(f\"Ascending: {sum(1 for x in selected_objects if x['class_id']==0)}\")\n",
    "    print(f\"Descending: {sum(1 for x in selected_objects if x['class_id']==1)}\")\n",
    "    print(f\"Passing: {sum(1 for x in selected_objects if x['class_id']==2)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c00705",
   "metadata": {},
   "source": [
    "## Analyze the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc30276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# Folder where you saved the returned Excel files from annotators\n",
    "ANNOTATOR_FILES_DIR = \"./returned_files\" \n",
    "\n",
    "# The Master Key file you generated earlier\n",
    "GROUND_TRUTH_FILE = \"Answer_Key_DO_NOT_SEND.xlsx\" \n",
    "# =================================================\n",
    "\n",
    "def clean_label(value):\n",
    "    \"\"\"Converts '0: Ascending' or 0 to integer 0\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return -1 # Missing value\n",
    "    str_val = str(value).strip()\n",
    "    if ':' in str_val:\n",
    "        return int(str_val.split(':')[0])\n",
    "    try:\n",
    "        return int(float(str_val))\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def main():\n",
    "    # 1. Load Ground Truth (Optional: strictly for your reference)\n",
    "    gt_df = pd.read_excel(GROUND_TRUTH_FILE)\n",
    "    print(f\"Loaded Ground Truth: {len(gt_df)} samples\")\n",
    "\n",
    "    # 2. Load Annotator Files\n",
    "    annotator_files = glob.glob(os.path.join(ANNOTATOR_FILES_DIR, \"*.xlsx\"))\n",
    "    print(f\"Found {len(annotator_files)} annotator files.\")\n",
    "    \n",
    "    if len(annotator_files) < 2:\n",
    "        print(\"Error: Need at least 2 annotator files to calculate Kappa.\")\n",
    "        return\n",
    "\n",
    "    # 3. Build the Agreement Matrix\n",
    "    # We need a DataFrame where columns are Annotators, rows are Images\n",
    "    df_merged = gt_df[['Image_ID']].copy()\n",
    "    \n",
    "    for file_path in annotator_files:\n",
    "        name = os.path.basename(file_path).replace(\".xlsx\", \"\")\n",
    "        # Read file\n",
    "        temp_df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Extract answers (assuming column B is 'Select Action (Click Cell)')\n",
    "        # If headers changed, check the index. Usually column 1 (0-index based).\n",
    "        # We look for the column that contains 'Select Action'\n",
    "        target_col = [c for c in temp_df.columns if \"Select Action\" in str(c)][0]\n",
    "        \n",
    "        # Clean and Merge\n",
    "        temp_df[name] = temp_df[target_col].apply(clean_label)\n",
    "        \n",
    "        # Merge on Image_ID to ensure alignment\n",
    "        # (Assumes Image_ID is in Column A)\n",
    "        id_col = [c for c in temp_df.columns if \"Image\" in str(c)][0]\n",
    "        temp_df = temp_df[[id_col, name]]\n",
    "        \n",
    "        df_merged = df_merged.merge(temp_df, left_on='Image_ID', right_on=id_col, how='left')\n",
    "        df_merged.drop(columns=[id_col], inplace=True)\n",
    "\n",
    "    # 4. Convert to Fleiss' Kappa Format\n",
    "    # Matrix: Rows = Subjects (Images), Cols = Categories (0, 1, 2)\n",
    "    # Value = Count of how many raters assigned that category\n",
    "    \n",
    "    annotator_cols = [c for c in df_merged.columns if c != 'Image_ID']\n",
    "    print(f\"Annotators included: {annotator_cols}\")\n",
    "    \n",
    "    # Filter out any rows with missing answers (-1)\n",
    "    valid_rows = df_merged[annotator_cols].ge(0).all(axis=1)\n",
    "    if not valid_rows.all():\n",
    "        print(f\"Warning: Dropping {sum(~valid_rows)} images due to missing answers.\")\n",
    "        df_merged = df_merged[valid_rows]\n",
    "\n",
    "    # Count votes for each category (0, 1, 2)\n",
    "    # Shape: (N_images, 3_categories)\n",
    "    N_categories = 3\n",
    "    fleiss_matrix = np.zeros((len(df_merged), N_categories))\n",
    "    \n",
    "    for i, row in df_merged.iterrows():\n",
    "        votes = row[annotator_cols].values\n",
    "        for vote in votes:\n",
    "            fleiss_matrix[i, int(vote)] += 1\n",
    "            \n",
    "    # 5. Calculate Kappa\n",
    "    kappa = fleiss_kappa(fleiss_matrix)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"FLEISS' KAPPA SCORE: {kappa:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Interpretation\n",
    "    if kappa < 0:\n",
    "        print(\"Interpretation: Poor agreement (Less than chance)\")\n",
    "    elif 0.01 <= kappa <= 0.20:\n",
    "        print(\"Interpretation: Slight agreement\")\n",
    "    elif 0.21 <= kappa <= 0.40:\n",
    "        print(\"Interpretation: Fair agreement\")\n",
    "    elif 0.41 <= kappa <= 0.60:\n",
    "        print(\"Interpretation: Moderate agreement\")\n",
    "    elif 0.61 <= kappa <= 0.80:\n",
    "        print(\"Interpretation: Substantial agreement\")\n",
    "    elif 0.81 <= kappa <= 1.00:\n",
    "        print(\"Interpretation: Almost perfect agreement\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0418cc",
   "metadata": {},
   "source": [
    "## Response Text: \"We conducted a blind annotation study with 5 independent raters. To ensure consistency, raters were provided with the standard annotation guidelines used in the original dataset creation (e.g., specifying that 'Descending' requires visible leg motion, otherwise classified as 'Passing' to reduce ambiguity). The resulting Fleiss' Kappa of 0.XX confirms that our strict definitions are reproducible...\"\n",
    "\n",
    "우리는 이미 처음 annotation을 수행할때 투표로 결정을 했었다.\n",
    "이번에 IAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
