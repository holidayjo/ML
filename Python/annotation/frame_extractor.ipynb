{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14748107",
   "metadata": {},
   "source": [
    "## From video, we can check the crop image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ae3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/holidayj/Documents/github/ML/Python/annotation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.video_utils import extract_frames_fast\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "VIDEO_PATH    = '/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/chungmuro_hasun_20221019T172940_20221019T203040.mp4'\n",
    "OUTPUT_FOLDER = 'frames/chungmuro_hasun_20221019_f1729_t2030_1frame_700'\n",
    "\n",
    "INTERVAL_SEC  = 1/3   # Extract 3 frames per second (approx)\n",
    "CROP_SIZE     = 700\n",
    "MARGIN_RIGHT  = 400\n",
    "MARGIN_TOP    = 30\n",
    "FILE_PREFIX   = \"chungmuro_frame\"\n",
    "\n",
    "def main():\n",
    "    extract_frames_fast(\n",
    "        video_path=VIDEO_PATH,\n",
    "        output_folder=OUTPUT_FOLDER,\n",
    "        interval_sec=INTERVAL_SEC,\n",
    "        crop_size=CROP_SIZE,\n",
    "        margin_right=MARGIN_RIGHT,\n",
    "        margin_top=MARGIN_TOP,\n",
    "        file_prefix=FILE_PREFIX\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7bd13",
   "metadata": {},
   "source": [
    "## From hd images, crop images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af8d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 4161 Images ---\n",
      "Original Size: 1920x1080\n",
      "Crop: 700x700 at (820, 30)\n",
      "Using 7 background processes for saving.\n",
      "Starting batch crop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4161/4161 [02:11<00:00, 31.58img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing finished. Waiting for file writes to complete...\n",
      "Done! Saved 4161 images to './cropped_images_700'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "SOURCE_FOLDER = \"/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/frames/chungmuro_hasun_10frame_1920_train_arrival\"\n",
    "OUTPUT_FOLDER = \"./cropped_images_700\"\n",
    "\n",
    "# Crop Parameters\n",
    "CROP_SIZE = 700\n",
    "MARGIN_RIGHT = 400\n",
    "MARGIN_TOP = 30\n",
    "\n",
    "def save_image_worker(args):\n",
    "    \"\"\"\n",
    "    Independent worker function to save the image.\n",
    "    (Reused from utils/video_utils.py pattern)\n",
    "    \"\"\"\n",
    "    img_data, save_path = args\n",
    "    cv2.imwrite(save_path, img_data)\n",
    "\n",
    "def process_existing_images(source_folder, output_folder, crop_size, margin_right, margin_top):\n",
    "    # 1. Setup\n",
    "    if not os.path.exists(source_folder):\n",
    "        print(f\"Error: Source folder not found at {source_folder}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get list of images (assuming .jpg, add .png if needed)\n",
    "    image_paths = sorted(glob.glob(os.path.join(source_folder, \"*.jpg\")))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(\"No .jpg images found in source folder.\")\n",
    "        return\n",
    "\n",
    "    # 2. Calculate Crop Coordinates based on the first image\n",
    "    first_img = cv2.imread(image_paths[0])\n",
    "    if first_img is None:\n",
    "        print(\"Error reading the first image.\")\n",
    "        return\n",
    "\n",
    "    h, width, _ = first_img.shape\n",
    "    \n",
    "    # Logic: x_start = width - margin_right - crop_size\n",
    "    x_start = width - margin_right - crop_size\n",
    "    y_start = margin_top\n",
    "    \n",
    "    # Boundary checks\n",
    "    if x_start < 0: x_start = 0\n",
    "    if y_start < 0: y_start = 0\n",
    "\n",
    "    print(f\"--- Processing {len(image_paths)} Images ---\")\n",
    "    print(f\"Original Size: {width}x{h}\")\n",
    "    print(f\"Crop: {crop_size}x{crop_size} at ({x_start}, {y_start})\")\n",
    "    \n",
    "    # 3. Initialize Worker Pool\n",
    "    worker_count = max(1, cpu_count() - 1)\n",
    "    print(f\"Using {worker_count} background processes for saving.\")\n",
    "    \n",
    "    pool = Pool(processes=worker_count)\n",
    "    saved_count = 0\n",
    "\n",
    "    # 4. Processing Loop\n",
    "    print(\"Starting batch crop...\")\n",
    "    \n",
    "    for img_path in tqdm(image_paths, unit=\"img\"):\n",
    "        # Read image in main process\n",
    "        frame = cv2.imread(img_path)\n",
    "        \n",
    "        if frame is None:\n",
    "            continue\n",
    "\n",
    "        # Crop Logic\n",
    "        cropped = frame[y_start : y_start + crop_size, \n",
    "                        x_start : x_start + crop_size]\n",
    "        \n",
    "        # Construct filename (keep original name)\n",
    "        filename = os.path.basename(img_path)\n",
    "        save_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # Async Save\n",
    "        pool.apply_async(save_image_worker, args=((cropped, save_path),))\n",
    "        saved_count += 1\n",
    "\n",
    "    # 5. Cleanup\n",
    "    print(\"\\nProcessing finished. Waiting for file writes to complete...\")\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(f\"Done! Saved {saved_count} images to '{output_folder}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_existing_images(SOURCE_FOLDER, OUTPUT_FOLDER, CROP_SIZE, MARGIN_RIGHT, MARGIN_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701e0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning reference directory...\n",
      "Found 4161 images in Source.\n",
      "Found 2769 files in Reference.\n",
      "Starting copy process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4161 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4161/4161 [00:00<00:00, 4760.19file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary ---\n",
      "Total processed: 4161\n",
      "Copied to TEMP1 (Matched): 1384\n",
      "Copied to TEMP2 (Rest):    2777\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7be7b3e",
   "metadata": {},
   "source": [
    "## Saving 1 frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9968de",
   "metadata": {},
   "source": [
    "## Finding Cropping area from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1fbf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for a valid Keyframe...\n",
      "Success: Valid frame found at index 1\n",
      "Original Resolution: 1920x1080\n",
      "Cropping Area -> X: 1280 to 1920, Y: 0 to 640\n",
      "Saved cropped image to: output_frames/cropped_700.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x3a1d3240] missing picture in access unit with size 40\n",
      "[h264 @ 0x3a1d3240] no frame!\n",
      "[h264 @ 0x3a0c2180] no frame!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "video_path      = '/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_20221019T172940-20221019T202940.mp4'\n",
    "output_folder   = 'output_frames'\n",
    "output_filename = 'cropped_700.jpg'\n",
    "# crop_size       = 600\n",
    "crop_size       = 700\n",
    "\n",
    "# Cropping Margins\n",
    "margin_top   = 30    # Move down pixels from the top edge\n",
    "margin_right = 400  # Move left 120 pixels from the right edge\n",
    "# ---------------------\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video at {video_path}\")\n",
    "else:\n",
    "    # 1. Search for the first valid frame (Fix for the [h264] error)\n",
    "    frame_found = False\n",
    "    max_attempts = 100\n",
    "    \n",
    "    print(\"Searching for a valid Keyframe...\")\n",
    "    \n",
    "    for i in range(max_attempts):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            print(f\"Success: Valid frame found at index {i}\")\n",
    "            \n",
    "            # --- CROP LOGIC STARTS HERE ---\n",
    "            \n",
    "            # 2. Get Dimensions\n",
    "            height, width, _ = frame.shape\n",
    "            \n",
    "            # 3. Calculate Coordinates\n",
    "            # Y: Start at top margin\n",
    "            y_start = margin_top\n",
    "            y_end = y_start + crop_size\n",
    "\n",
    "            # X: Start from right side (width) - margin - crop_size\n",
    "            x_end = width - margin_right\n",
    "            x_start = x_end - crop_size\n",
    "\n",
    "            print(f\"Original Resolution: {width}x{height}\")\n",
    "            print(f\"Cropping Area -> X: {x_start} to {x_end}, Y: {y_start} to {y_end}\")\n",
    "\n",
    "            # 4. Perform Crop\n",
    "            cropped_frame = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            # 5. Save\n",
    "            full_save_path = os.path.join(output_folder, output_filename)\n",
    "            cv2.imwrite(full_save_path, cropped_frame)\n",
    "            print(f\"Saved cropped image to: {full_save_path}\")\n",
    "            \n",
    "            frame_found = True\n",
    "            break # Stop after saving the first valid frame\n",
    "            \n",
    "            # --- CROP LOGIC ENDS HERE ---\n",
    "\n",
    "    if not frame_found:\n",
    "        print(\"Error: Could not find any valid frames in the beginning of the video.\")\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4daee6",
   "metadata": {},
   "source": [
    "# Cropping area from the full frame images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285ac949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4945 images. Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4945/4945 [02:52<00:00, 28.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! 4945 images saved to:\n",
      "/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival/cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm  # Optional: for a progress bar, run 'pip install tqdm' if missing\n",
    "\n",
    "# 1. Configuration\n",
    "source_dir = \"/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival\"\n",
    "output_dir = os.path.join(source_dir, \"cropped\")\n",
    "CROP_W, CROP_H = 640, 640\n",
    "\n",
    "# 2. Setup\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "# Get list of images\n",
    "files = [f for f in os.listdir(source_dir) if f.lower().endswith(image_extensions)]\n",
    "print(f\"Found {len(files)} images. Processing...\")\n",
    "\n",
    "# 3. Processing Loop\n",
    "count = 0\n",
    "for filename in tqdm(files):\n",
    "    file_path = os.path.join(source_dir, filename)\n",
    "    \n",
    "    # Read Image\n",
    "    img = cv2.imread(file_path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not read {filename}\")\n",
    "        continue\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    # Check if image is large enough\n",
    "    if w < CROP_W or h < CROP_H:\n",
    "        print(f\"Skipping {filename}: Image smaller than crop size ({w}x{h})\")\n",
    "        continue\n",
    "\n",
    "    # 4. Calculate Top-Right Coordinates\n",
    "    # Y: Starts at 0, ends at 640\n",
    "    # X: Starts at (Width - 640), ends at Width\n",
    "    x_start = w - CROP_W\n",
    "    y_start = 0\n",
    "    \n",
    "    # Crop: img[y:y+h, x:x+w]\n",
    "    cropped_img = img[y_start : y_start + CROP_H, x_start : x_start + CROP_W]\n",
    "    \n",
    "    # 5. Save\n",
    "    save_path = os.path.join(output_dir, filename)\n",
    "    cv2.imwrite(save_path, cropped_img)\n",
    "    count += 1\n",
    "\n",
    "print(f\"\\nDone! {count} images saved to:\\n{output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98284c5",
   "metadata": {},
   "source": [
    "## Put cropped images into set1 to set5 folders. (Round Robin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5967aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4945 images. Distributing cyclically into 5 sets...\n",
      "Done! Distribution complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 1. Configuration\n",
    "base_dir = \"/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival/cropped\"\n",
    "num_sets = 5\n",
    "\n",
    "# 2. Get and Sort Files\n",
    "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "files = [f for f in os.listdir(base_dir) if f.lower().endswith(valid_exts)]\n",
    "files.sort() # Important to keep the sequence (1st, 2nd, 3rd...)\n",
    "\n",
    "print(f\"Found {len(files)} images. Distributing cyclically into {num_sets} sets...\")\n",
    "\n",
    "# Create the set folders first\n",
    "for i in range(1, num_sets + 1):\n",
    "    os.makedirs(os.path.join(base_dir, f\"set{i}\"), exist_ok=True)\n",
    "\n",
    "# 3. Distribute Files Round-Robin\n",
    "for index, filename in enumerate(files):\n",
    "    # Calculate which set (0 to 4) -> (1 to 5)\n",
    "    # 0 % 5 = 0 -> set1\n",
    "    # 1 % 5 = 1 -> set2\n",
    "    # ...\n",
    "    # 5 % 5 = 0 -> set1\n",
    "    set_num = (index % num_sets) + 1\n",
    "    \n",
    "    src_path = os.path.join(base_dir, filename)\n",
    "    dst_path = os.path.join(base_dir, f\"set{set_num}\", filename)\n",
    "    \n",
    "    shutil.move(src_path, dst_path)\n",
    "\n",
    "print(\"Done! Distribution complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa3b26",
   "metadata": {},
   "source": [
    "## Extracting full frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff455ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 29.99988184680194\n",
      "Start Time: 07:00:00\n",
      "Total Frames: 329994\n",
      "Saving to: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20251111_f0700_t1000/10frames\n",
      "Extracting 33000 frames (Step: 10) using 8 CPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33000/33000 [24:03<00:00, 22.86img/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Files saved with timestamp in name (e.g., euljiro_070001_frame_xxxxxx.jpg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "VIDEO_PATH    = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20251111_f0700_t1000/euljiro_inner_20251111_f0700_t1000.mp4'\n",
    "OUTPUT_FOLDER = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20251111_f0700_t1000/10frames'\n",
    "\n",
    "# Video Start Time (Hour, Minute, Second)\n",
    "START_TIME_STR = \"07:00:00\"\n",
    "\n",
    "FRAME_STEP    = 10\n",
    "CROP_SIZE     = 320\n",
    "MARGIN_RIGHT  = 120\n",
    "MARGIN_TOP    = 0\n",
    "# ---------------------\n",
    "\n",
    "def extract_frames_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function to be run by each CPU core.\n",
    "    Now accepts 'fps' and 'start_time_obj' to calculate timestamps.\n",
    "    \"\"\"\n",
    "    video_path, frames_to_process, (dir_crop, dir_orig), (x_start, y_start), fps, start_dt = args\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    \n",
    "    for frame_idx in frames_to_process:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # --- Calculate Timestamp ---\n",
    "            # Seconds elapsed = frame_number / fps\n",
    "            seconds_elapsed = frame_idx / fps\n",
    "            \n",
    "            # Add to start time\n",
    "            current_time = start_dt + timedelta(seconds=seconds_elapsed)\n",
    "            \n",
    "            # Format: HHMMSS (e.g., 070001)\n",
    "            time_str = current_time.strftime(\"%H%M%S\")\n",
    "            \n",
    "            # New Filename: euljiro_070001_frame_000030.jpg\n",
    "            filename = f\"euljiro_{time_str}_frame_{frame_idx:06d}.jpg\"\n",
    "\n",
    "            # 1. Save Original\n",
    "            path_orig = os.path.join(dir_orig, filename)\n",
    "            cv2.imwrite(path_orig, frame)\n",
    "\n",
    "            # 2. Save Cropped\n",
    "            cropped = frame[y_start : y_start + CROP_SIZE, \n",
    "                            x_start : x_start + CROP_SIZE]\n",
    "            \n",
    "            path_crop = os.path.join(dir_crop, filename)\n",
    "            cv2.imwrite(path_crop, cropped)\n",
    "            count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return count\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Folders\n",
    "    dir_crop = os.path.join(OUTPUT_FOLDER, 'cropped')\n",
    "    dir_orig = os.path.join(OUTPUT_FOLDER, 'original')\n",
    "    os.makedirs(dir_crop, exist_ok=True)\n",
    "    os.makedirs(dir_orig, exist_ok=True)\n",
    "\n",
    "    # 2. Parse Start Time\n",
    "    # We use a dummy date (today) because timedelta requires a datetime object\n",
    "    start_dt = datetime.strptime(START_TIME_STR, \"%H:%M:%S\")\n",
    "\n",
    "    # 3. Analyze Video Metadata\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video at {VIDEO_PATH}\")\n",
    "        return\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    cap.release()\n",
    "\n",
    "    # 4. Config\n",
    "    x_start = width - MARGIN_RIGHT - CROP_SIZE\n",
    "    y_start = MARGIN_TOP\n",
    "    \n",
    "    print(f\"Video FPS: {fps}\")\n",
    "    print(f\"Start Time: {START_TIME_STR}\")\n",
    "    print(f\"Total Frames: {total_frames}\")\n",
    "    print(f\"Saving to: {OUTPUT_FOLDER}\")\n",
    "\n",
    "    # 5. Generate Target Indices (Every 10 frames)\n",
    "    target_indices = list(range(0, total_frames, FRAME_STEP))\n",
    "    \n",
    "    print(f\"Extracting {len(target_indices)} frames (Step: {FRAME_STEP}) using {cpu_count()} CPUs...\")\n",
    "\n",
    "    # 6. Distribute work\n",
    "    num_cpus = cpu_count()\n",
    "    chunk_size = math.ceil(len(target_indices) / num_cpus)\n",
    "    \n",
    "    tasks = []\n",
    "    for i in range(0, len(target_indices), chunk_size):\n",
    "        chunk = target_indices[i : i + chunk_size]\n",
    "        # Pass fps and start_dt to worker\n",
    "        tasks.append((VIDEO_PATH, chunk, (dir_crop, dir_orig), (x_start, y_start), fps, start_dt))\n",
    "\n",
    "    # 7. Execute\n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        with tqdm(total=len(target_indices), unit=\"img\") as pbar:\n",
    "            for saved_count in pool.imap_unordered(extract_frames_worker, tasks):\n",
    "                pbar.update(saved_count)\n",
    "\n",
    "    print(\"Done! Files saved with timestamp in name (e.g., euljiro_070001_frame_xxxxxx.jpg)\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc333ca",
   "metadata": {},
   "source": [
    "## Extracting frames and crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 30.0 | Step: 10\n",
      "Using 8 CPUs for saving images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x3e6630c0] missing picture in access unit with size 40\n",
      "[h264 @ 0x3e6630c0] no frame!\n",
      "  0%|          | 0/325817 [00:00<?, ?frame/s][h264 @ 0x3dde2580] no frame!\n",
      "  0%|          | 881/325817 [00:02<17:25, 310.94frame/s]Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-17:\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/queues.py\", line 385, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/holidayj/anaconda3/envs/hj/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDone! Saved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msaved_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m images.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=total_frames, unit=\u001b[33m\"\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m current_idx < \u001b[32m100\u001b[39m: \u001b[38;5;66;03m# Skip initial corruption\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "# chungmuro hasun config.\n",
    "VIDEO_PATH    = '/media/holidayj/Documents/Videos/videos/platform/euljiro/euljoro_20251111_070000.mp4'\n",
    "OUTPUT_FOLDER = '/media/holidayj/Documents/data/frames/euljiro_rush_20251111'\n",
    "INTERVAL_SEC  = 0.2\n",
    "CROP_SIZE     = 600\n",
    "MARGIN_RIGHT  = 400\n",
    "MARGIN_TOP    = 10\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "VIDEO_PATH    = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/euljiro_inner_20221101_f1700_t2000.mp4'\n",
    "# VIDEO_PATH    = '/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/chungmuro_hasun_20221019T172940_20221019T203040.mp4'\n",
    "# VIDEO_PATH    = '/home/holidayj/Videos/videos/platform/chungmuro/chungmuro_sangsun_20221019T172940-20221019T202940/chungmuro_sangsun_20221019T172940-20221019T202940.mp4'\n",
    "\n",
    "OUTPUT_FOLDER = 'frames/euljiro_inner_20221101_f1700_t2000_1sec'\n",
    "INTERVAL_SEC  = 1/3\n",
    "CROP_SIZE     = 700\n",
    "MARGIN_RIGHT  = 400\n",
    "MARGIN_TOP    = 30\n",
    "\n",
    "\n",
    "\n",
    "# OUTPUT_FOLDER = 'frames/chungmuro_hasun_6frames_700'\n",
    "# INTERVAL_SEC  = 0.2\n",
    "# CROP_SIZE     = 700\n",
    "# MARGIN_RIGHT  = 400\n",
    "# MARGIN_TOP    = 30\n",
    "# ---------------------\n",
    "\n",
    "def save_image_worker(args):\n",
    "    \"\"\"\n",
    "    Independent worker function to save the image.\n",
    "    This runs on separate CPUs.\n",
    "    \"\"\"\n",
    "    img_data, save_path = args\n",
    "    cv2.imwrite(save_path, img_data)\n",
    "\n",
    "def main():\n",
    "    # 1. Setup\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video.\")\n",
    "        return\n",
    "\n",
    "    # 2. Metadata\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = np.round(cap.get(cv2.CAP_PROP_FPS))\n",
    "    # print(\"fps =\", np.round(fps))\n",
    "    \n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    \n",
    "    # 3. Crop Config\n",
    "    x_start = width - MARGIN_RIGHT - CROP_SIZE\n",
    "    y_start = MARGIN_TOP\n",
    "    frame_step = int(fps * INTERVAL_SEC)\n",
    "    if frame_step < 1: frame_step = 1\n",
    "\n",
    "    print(f\"FPS: {fps} | Step: {frame_step}\")\n",
    "    print(f\"Using {cpu_count()} CPUs for saving images.\")\n",
    "\n",
    "    # 4. Initialize the Worker Pool (For saving only)\n",
    "    # We use roughly 80% of CPUs to leave room for the main reader process\n",
    "    worker_count = max(1, cpu_count() - 1) \n",
    "    pool = Pool(processes=worker_count)\n",
    "    \n",
    "    current_idx = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    # 5. Fast Reader Loop\n",
    "    # The main loop now NEVER waits for disk I/O. \n",
    "    # It just throws the image to the pool and immediately reads the next one.\n",
    "    with tqdm(total=total_frames, unit=\"frame\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                if current_idx < 100: # Skip initial corruption\n",
    "                    current_idx += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if current_idx % frame_step == 0:\n",
    "                # Crop\n",
    "                cropped = frame[0:1080,\n",
    "                                0:1920]\n",
    "                cropped = frame[y_start : y_start + CROP_SIZE, \n",
    "                                x_start : x_start + CROP_SIZE]\n",
    "                \n",
    "                # Construct path\n",
    "                filename = f\"chungmuro_frame_{current_idx:06d}.jpg\"\n",
    "                save_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "                \n",
    "                # --- ASYNC SAVE ---\n",
    "                # Fire and forget. The main loop continues immediately.\n",
    "                pool.apply_async(save_image_worker, args=((cropped, save_path),))\n",
    "                saved_count += 1\n",
    "\n",
    "            current_idx += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    print(\"\\nReading finished. Waiting for remaining file writes to complete...\")\n",
    "    pool.close()\n",
    "    pool.join() # Wait for the background workers to finish saving\n",
    "    print(f\"Done! Saved {saved_count} images.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8049ed",
   "metadata": {},
   "source": [
    "# This code select frames only those divisible by 30, and crops to get the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f11241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files in: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival\n",
      "Image Size: 1920x1080\n",
      "Crop X: 820 ~ 1520 (Width: 700)\n",
      "Crop Y: 30 ~ 730 (Height: 700)\n",
      "Filtering for every 30th frame...\n",
      "Found 1384 frames to process.\n",
      "Processing with 8 CPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384/1384 [00:15<00:00, 90.24img/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Cropped images saved to: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SOURCE_FOLDER = '/media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival'\n",
    "OUTPUT_FOLDER = os.path.join(SOURCE_FOLDER, '30_frames_crop')\n",
    "\n",
    "# Filter Condition: Every 30 frames (0, 30, 60, 90...)\n",
    "TARGET_FRAME_STEP = 30\n",
    "\n",
    "# Crop Configuration\n",
    "CROP_SIZE     = 700   # 700x700 square\n",
    "MARGIN_RIGHT  = 400\n",
    "MARGIN_TOP    = 30\n",
    "# ---------------------\n",
    "\n",
    "def crop_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function to read an image, crop it, and save it.\n",
    "    args: (file_path, save_path, crop_coords)\n",
    "    crop_coords: (y_start, y_end, x_start, x_end)\n",
    "    \"\"\"\n",
    "    file_path, save_path, (y_s, y_e, x_s, x_e) = args\n",
    "    \n",
    "    img = cv2.imread(file_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    # Crop the image using numpy slicing [y:y+h, x:x+w]\n",
    "    cropped_img = img[y_s:y_e, x_s:x_e]\n",
    "    \n",
    "    cv2.imwrite(save_path, cropped_img)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Folders\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "    # 2. Get list of all images\n",
    "    print(f\"Scanning files in: {SOURCE_FOLDER}\")\n",
    "    all_files = glob.glob(os.path.join(SOURCE_FOLDER, \"*.jpg\"))\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"Error: No images found in source folder.\")\n",
    "        return\n",
    "\n",
    "    # 3. Calculate Crop Coordinates (Based on the first image found)\n",
    "    # We assume all images have the same resolution (likely 1920x1080)\n",
    "    sample_img = cv2.imread(all_files[0])\n",
    "    img_h, img_w = sample_img.shape[:2]\n",
    "    \n",
    "    # Logic: Start X = Width - Margin_Right - Crop_Size\n",
    "    x_start = img_w - MARGIN_RIGHT - CROP_SIZE\n",
    "    x_end   = x_start + CROP_SIZE\n",
    "    y_start = MARGIN_TOP\n",
    "    y_end   = y_start + CROP_SIZE\n",
    "    \n",
    "    crop_coords = (y_start, y_end, x_start, x_end)\n",
    "    \n",
    "    print(f\"Image Size: {img_w}x{img_h}\")\n",
    "    print(f\"Crop X: {x_start} ~ {x_end} (Width: {CROP_SIZE})\")\n",
    "    print(f\"Crop Y: {y_start} ~ {y_end} (Height: {CROP_SIZE})\")\n",
    "\n",
    "    # 4. Filter files: Only keep frames where number % 30 == 0\n",
    "    tasks = []\n",
    "    print(f\"Filtering for every {TARGET_FRAME_STEP}th frame...\")\n",
    "    \n",
    "    for file_path in all_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        # Parse frame number from \"chungmuro_frame_002060.jpg\"\n",
    "        try:\n",
    "            # Split by '_' take last part, remove .jpg extension\n",
    "            frame_part = filename.split('_')[-1] \n",
    "            frame_str = frame_part.split('.')[0]\n",
    "            frame_num = int(frame_str)\n",
    "            \n",
    "            # CHECK CONDITION\n",
    "            if frame_num % TARGET_FRAME_STEP == 0:\n",
    "                save_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "                tasks.append((file_path, save_path, crop_coords))\n",
    "                \n",
    "        except ValueError:\n",
    "            # Skip files that don't match the naming pattern\n",
    "            continue\n",
    "\n",
    "    print(f\"Found {len(tasks)} frames to process.\")\n",
    "    \n",
    "    # 5. Execute Parallel Processing\n",
    "    num_cpus = cpu_count()\n",
    "    print(f\"Processing with {num_cpus} CPUs...\")\n",
    "    \n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        # Use imap to show progress bar\n",
    "        list(tqdm(pool.imap(crop_worker, tasks), total=len(tasks), unit=\"img\"))\n",
    "\n",
    "    print(f\"\\nSuccess! Cropped images saved to: {OUTPUT_FOLDER}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1c2ca",
   "metadata": {},
   "source": [
    "# Applying CLAHE\n",
    "Too much noise? Decrease CLIP_LIMIT from 3.0 to 2.0.\n",
    "\n",
    "Still too dark? Increase CLIP_LIMIT to 4.0 or 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bd16d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files in: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop\n",
      "Found 1384 images. Applying CLAHE (ClipLimit=5.0)...\n",
      "Processing with 8 CPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384/1384 [00:30<00:00, 45.89img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Enhanced images saved to: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop/clahe\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# The folder containing the already cropped images\n",
    "INPUT_FOLDER = '/media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop'\n",
    "\n",
    "# The new subfolder for CLAHE images\n",
    "OUTPUT_FOLDER = os.path.join(INPUT_FOLDER, 'clahe')\n",
    "\n",
    "# CLAHE Settings\n",
    "# clipLimit: Higher = more contrast (and more noise). 2.0 to 4.0 is standard.\n",
    "# tileGridSize: Size of the local area to inspect. (8,8) is standard.\n",
    "CLIP_LIMIT = 5.0 \n",
    "GRID_SIZE = (8, 8)\n",
    "# ---------------------\n",
    "\n",
    "def clahe_worker(args):\n",
    "    \"\"\"\n",
    "    Reads an image, applies CLAHE to the Lightness channel, and saves it.\n",
    "    \"\"\"\n",
    "    file_path, save_path = args\n",
    "    \n",
    "    img = cv2.imread(file_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    # 1. Convert BGR to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # 2. Split into L, A, B channels\n",
    "    l_channel, a, b = cv2.split(lab)\n",
    "\n",
    "    # 3. Apply CLAHE to L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=CLIP_LIMIT, tileGridSize=GRID_SIZE)\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # 4. Merge the CLAHE enhanced L-channel with the original A and B channels\n",
    "    merged_lab = cv2.merge((cl, a, b))\n",
    "\n",
    "    # 5. Convert back to BGR\n",
    "    final_img = cv2.cvtColor(merged_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    cv2.imwrite(save_path, final_img)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Folders\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "    # 2. Get list of cropped images\n",
    "    print(f\"Scanning files in: {INPUT_FOLDER}\")\n",
    "    all_files = glob.glob(os.path.join(INPUT_FOLDER, \"*.jpg\"))\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"Error: No images found. Make sure you ran the crop script first.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(all_files)} images. Applying CLAHE (ClipLimit={CLIP_LIMIT})...\")\n",
    "\n",
    "    # 3. Prepare Tasks\n",
    "    tasks = []\n",
    "    for file_path in all_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        save_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "        tasks.append((file_path, save_path))\n",
    "    \n",
    "    # 4. Execute Parallel Processing\n",
    "    num_cpus = cpu_count()\n",
    "    print(f\"Processing with {num_cpus} CPUs...\")\n",
    "    \n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        list(tqdm(pool.imap(clahe_worker, tasks), total=len(tasks), unit=\"img\"))\n",
    "\n",
    "    print(f\"\\nDone! Enhanced images saved to: {OUTPUT_FOLDER}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17c741",
   "metadata": {},
   "source": [
    "# Moving images into 2 folders\n",
    "Frame 0: Index 0 (Even) $\\rightarrow$ set_1\n",
    "\n",
    "Frame 30: Index 1 (Odd) $\\rightarrow$ set_2\n",
    "\n",
    "Frame 60: Index 2 (Even) $\\rightarrow$ set_1\n",
    "\n",
    "Frame 90: Index 3 (Odd) $\\rightarrow$ set_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf10cec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files in: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop/clahe\n",
      "Found 1384 images. Splitting...\n",
      "------------------------------\n",
      "Total processed: 1384\n",
      "Moved to Set 1:  692 images\n",
      "Moved to Set 2:  692 images\n",
      "------------------------------\n",
      "Location 1: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop/clahe/set_1\n",
      "Location 2: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop/clahe/set_2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# The folder containing the CLAHE images\n",
    "INPUT_FOLDER = '/media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop/clahe'\n",
    "\n",
    "# The two output folders\n",
    "FOLDER_1 = os.path.join(INPUT_FOLDER, 'set_1')\n",
    "FOLDER_2 = os.path.join(INPUT_FOLDER, 'set_2')\n",
    "# ---------------------\n",
    "\n",
    "def main():\n",
    "    # 1. Create output folders\n",
    "    os.makedirs(FOLDER_1, exist_ok=True)\n",
    "    os.makedirs(FOLDER_2, exist_ok=True)\n",
    "\n",
    "    # 2. Get list of files\n",
    "    # We must sort them to ensure the \"alternating\" logic follows the frame order\n",
    "    print(f\"Scanning files in: {INPUT_FOLDER}\")\n",
    "    files = glob.glob(os.path.join(INPUT_FOLDER, \"*.jpg\"))\n",
    "    files.sort()  # Crucial: Ensures we process frame_0, frame_1, frame_2 in order\n",
    "\n",
    "    if not files:\n",
    "        print(\"Error: No images found to split.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files)} images. Splitting...\")\n",
    "\n",
    "    count_1 = 0\n",
    "    count_2 = 0\n",
    "\n",
    "    # 3. Iterate and Move\n",
    "    for i, file_path in enumerate(files):\n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        # If index is Even (0, 2, 4...) -> Set 1\n",
    "        # If index is Odd  (1, 3, 5...) -> Set 2\n",
    "        if i % 2 == 0:\n",
    "            dest_path = os.path.join(FOLDER_1, filename)\n",
    "            count_1 += 1\n",
    "        else:\n",
    "            dest_path = os.path.join(FOLDER_2, filename)\n",
    "            count_2 += 1\n",
    "            \n",
    "        shutil.move(file_path, dest_path)\n",
    "        # Use shutil.copy(file_path, dest_path) if you don't want to delete originals\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total processed: {len(files)}\")\n",
    "    print(f\"Moved to Set 1:  {count_1} images\")\n",
    "    print(f\"Moved to Set 2:  {count_2} images\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Location 1: {FOLDER_1}\")\n",
    "    print(f\"Location 2: {FOLDER_2}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4754836",
   "metadata": {},
   "source": [
    "# Counting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5168e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2741 label files in /media/holidayj/Documents/data/euljiro_2nd/with_descending\n",
      "Error reading /media/holidayj/Documents/data/euljiro_2nd/with_descending/classes.txt: invalid literal for int() with base 10: 'U'\n",
      "\n",
      "Object counts per class:\n",
      "Class 0: 2600\n",
      "Class 1: 3473\n",
      "Class 2: 5312\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the path to your dataset\n",
    "dataset_path = '/media/holidayj/Documents/data/euljiro_2nd/with_descending'\n",
    "\n",
    "# Find all .txt files in the directory\n",
    "label_files = glob.glob(os.path.join(dataset_path, '*.txt'))\n",
    "\n",
    "print(f\"Found {len(label_files)} label files in {dataset_path}\")\n",
    "\n",
    "# Initialize a dictionary to count objects per class\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Iterate through each label file\n",
    "for file_path in label_files:\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                # Ensure the line is not empty\n",
    "                if parts:\n",
    "                    # In YOLO format, the first element is the class ID\n",
    "                    class_id = int(parts[0])\n",
    "                    class_counts[class_id] += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nObject counts per class:\")\n",
    "# Sort by class ID for cleaner output\n",
    "for class_id in sorted(class_counts.keys()):\n",
    "    print(f\"Class {class_id}: {class_counts[class_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deae4f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 5072 files...\n",
      "Error processing classes.txt: invalid literal for int() with base 10: 'U'\n",
      "---\n",
      "Process complete. Moved 2533 pairs to '/media/holidayj/Documents/data/euljiro_2nd/without_descending'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# --- Configuration ---\n",
    "source_dir = '/media/holidayj/Documents/data/euljiro_2nd'\n",
    "target_folder_name = 'without_descending'\n",
    "target_dir = os.path.join(source_dir, target_folder_name)\n",
    "target_class = 1  # The class ID for \"descending\"\n",
    "\n",
    "# --- Setup ---\n",
    "# Create the destination directory if it doesn't exist\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "    print(f\"Created directory: {target_dir}\")\n",
    "\n",
    "# Get list of all label files\n",
    "label_files = glob.glob(os.path.join(source_dir, '*.txt'))\n",
    "moved_count = 0\n",
    "\n",
    "print(f\"Scanning {len(label_files)} files...\")\n",
    "\n",
    "# --- Processing ---\n",
    "for label_path in label_files:\n",
    "    filename = os.path.basename(label_path)\n",
    "    file_base_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    has_descending = False\n",
    "    \n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) > 0:\n",
    "                    class_id = int(parts[0])\n",
    "                    if class_id == target_class:\n",
    "                        has_descending = True\n",
    "                        break  # Stop checking this file if we found class 1\n",
    "        \n",
    "        # If NO descending class was found, move the files\n",
    "        if not has_descending:\n",
    "            # 1. Move the Label file\n",
    "            shutil.move(label_path, os.path.join(target_dir, filename))\n",
    "            \n",
    "            # 2. Find and Move the Image file\n",
    "            # We check common image extensions\n",
    "            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "            image_found = False\n",
    "            \n",
    "            for ext in image_extensions:\n",
    "                image_name = file_base_name + ext\n",
    "                src_image_path = os.path.join(source_dir, image_name)\n",
    "                \n",
    "                if os.path.exists(src_image_path):\n",
    "                    shutil.move(src_image_path, os.path.join(target_dir, image_name))\n",
    "                    image_found = True\n",
    "                    break # Stop checking extensions once image is found\n",
    "            \n",
    "            moved_count += 1\n",
    "            if not image_found:\n",
    "                print(f\"Warning: Moved label {filename}, but could not find corresponding image.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(\"---\")\n",
    "print(f\"Process complete. Moved {moved_count} pairs to '{target_dir}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the directories\n",
    "# Where the JPGs are currently located (and where TXTs should go)\n",
    "target_dir = '/media/holidayj/Documents/data/euljiro_2nd/without_descending/descent'\n",
    "\n",
    "# Where the TXTs are currently located\n",
    "source_txt_dir = '/media/holidayj/Documents/data/euljiro_2nd/without_descending'\n",
    "\n",
    "# Counter to track progress\n",
    "count = 0\n",
    "\n",
    "# Iterate through all files in the target directory (the descent folder)\n",
    "for filename in os.listdir(target_dir):\n",
    "    # Check if the file is a JPG\n",
    "    if filename.lower().endswith('.jpg'):\n",
    "        \n",
    "        # Extract the filename without the extension (e.g., 'image_01')\n",
    "        file_root = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Construct the expected text file name\n",
    "        txt_filename = file_root + '.txt'\n",
    "        \n",
    "        # Define the full path for the source text file\n",
    "        src_txt_path = os.path.join(source_txt_dir, txt_filename)\n",
    "        \n",
    "        # Define the full destination path\n",
    "        dst_txt_path = os.path.join(target_dir, txt_filename)\n",
    "        \n",
    "        # Check if the corresponding text file exists in the source directory\n",
    "        if os.path.exists(src_txt_path):\n",
    "            try:\n",
    "                # Move the file\n",
    "                shutil.move(src_txt_path, dst_txt_path)\n",
    "                print(f\"Matched and Moved: {txt_filename}\")\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving {txt_filename}: {e}\")\n",
    "\n",
    "print(f\"---\")\n",
    "print(f\"Operation Complete. Total files moved: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "741a0e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5430 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 5430/5430 [03:13<00:00, 28.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete! \n",
      "Images saved to: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_60frames_700/equalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm  # Progress bar (optional, install with `pip install tqdm`)\n",
    "\n",
    "# 1. Define paths\n",
    "input_folder = '/media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_60frames_700'\n",
    "output_folder = os.path.join(input_folder, 'equalized')\n",
    "\n",
    "# 2. Create output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 3. Get list of all jpg images\n",
    "image_files = glob.glob(os.path.join(input_folder, '*.jpg'))\n",
    "print(f\"Found {len(image_files)} images.\")\n",
    "\n",
    "# 4. Process images\n",
    "for img_path in tqdm(image_files, desc=\"Processing\"):\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to read: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    # Convert from BGR to YCrCb (we want to equalize luminance 'Y', not colors)\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Equalize the histogram of the Y channel\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\n",
    "    # Convert back to BGR\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "    # Save the result\n",
    "    filename = os.path.basename(img_path)\n",
    "    save_path = os.path.join(output_folder, filename)\n",
    "    cv2.imwrite(save_path, img_output)\n",
    "\n",
    "print(f\"\\nProcessing complete! \\nImages saved to: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b522891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning source: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/euljiro_2nd/with_descending_ung_1120\n",
      "Found 0 existing reference frames.\n",
      "Analyzing gaps (Target: 50 < gap < 70)...\n",
      "----------------------------------------\n",
      "Plan saved to: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_1sec_re/extraction_plan.csv\n",
      "Total frames to extract: 0\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "----------------------------------------\n",
      "Starting extraction from VIDEO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0frame [00:00, ?frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! CSV and images saved to: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_1sec_re\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "VIDEO_PATH     = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/euljiro_inner_20221101_f1700_t2000.mp4'\n",
    "SOURCE_IMG_DIR = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/euljiro_2nd/with_descending_ung_1120'\n",
    "OUTPUT_ROOT    = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_1sec_re'\n",
    "\n",
    "# Gap Thresholds (Frames)\n",
    "# \"Approx 58~59 frames\". We need a small buffer.\n",
    "# If gap is > MAX_GAP, we assume \"No Train\" and skip the middle frame.\n",
    "MIN_GAP = 50 \n",
    "MAX_GAP = 70  # Allow slight jitter above 60 (e.g. 61-62) but block long pauses\n",
    "\n",
    "# Crop Config\n",
    "CROP_SIZE     = 320\n",
    "MARGIN_RIGHT  = 120\n",
    "MARGIN_TOP    = 0\n",
    "# ---------------------\n",
    "\n",
    "def parse_frame_number(filename):\n",
    "    \"\"\"Extracts 120 from 'euljiro_frame_000120.jpg'\"\"\"\n",
    "    try:\n",
    "        name_no_ext = os.path.splitext(filename)[0]\n",
    "        # flexible parsing: grabs the last chunk after underscore\n",
    "        num_str = name_no_ext.split('_')[-1]\n",
    "        return int(num_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_frames_worker(args):\n",
    "    \"\"\"\n",
    "    Worker: Opens video, extracts listed frames, saves Original & Crop.\n",
    "    \"\"\"\n",
    "    video_path, frames_to_process, (dir_orig, dir_crop), (x_start, y_start) = args\n",
    "    \n",
    "    # Sort for efficient seeking\n",
    "    frames_to_process.sort()\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    \n",
    "    for frame_idx in frames_to_process:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            filename = f\"euljiro_frame_{frame_idx:06d}.jpg\"\n",
    "\n",
    "            # 1. Save Original\n",
    "            cv2.imwrite(os.path.join(dir_orig, filename), frame)\n",
    "\n",
    "            # 2. Crop & Save\n",
    "            cropped = frame[y_start : y_start + CROP_SIZE, \n",
    "                            x_start : x_start + CROP_SIZE]\n",
    "            cv2.imwrite(os.path.join(dir_crop, filename), cropped)\n",
    "            count += 1\n",
    "            \n",
    "    cap.release()\n",
    "    return count\n",
    "\n",
    "def main():\n",
    "    # 1. Setup\n",
    "    dir_crop = os.path.join(OUTPUT_ROOT, 'cropped')\n",
    "    dir_orig = os.path.join(OUTPUT_ROOT, 'original')\n",
    "    os.makedirs(dir_crop, exist_ok=True)\n",
    "    os.makedirs(dir_orig, exist_ok=True)\n",
    "\n",
    "    # 2. Scan Existing Frames\n",
    "    print(f\"Scanning source: {SOURCE_IMG_DIR}\")\n",
    "    src_files = glob.glob(os.path.join(SOURCE_IMG_DIR, \"*.jpg\"))\n",
    "    existing_frames = []\n",
    "    for f in src_files:\n",
    "        num = parse_frame_number(os.path.basename(f))\n",
    "        if num is not None:\n",
    "            existing_frames.append(num)\n",
    "    \n",
    "    existing_frames.sort()\n",
    "    print(f\"Found {len(existing_frames)} existing reference frames.\")\n",
    "\n",
    "    # 3. Analyze Gaps & Build Plan\n",
    "    extraction_list = [] # Final list of all frames to extract\n",
    "    csv_data = []        # For reporting\n",
    "\n",
    "    print(f\"Analyzing gaps (Target: {MIN_GAP} < gap < {MAX_GAP})...\")\n",
    "\n",
    "    for i in range(len(existing_frames) - 1):\n",
    "        curr_fr = existing_frames[i]\n",
    "        next_fr = existing_frames[i+1]\n",
    "        gap = next_fr - curr_fr\n",
    "        \n",
    "        # Always add the 'current' existing frame to the extraction list\n",
    "        extraction_list.append(curr_fr)\n",
    "\n",
    "        # Logic: Check if we should insert a middle frame\n",
    "        middle_fr = 0\n",
    "        status = \"Skipped (Gap too large/small)\"\n",
    "        \n",
    "        if MIN_GAP <= gap <= MAX_GAP:\n",
    "            middle_fr = curr_fr + (gap // 2)\n",
    "            extraction_list.append(middle_fr)\n",
    "            status = \"Middle Frame Added\"\n",
    "        \n",
    "        # Add to CSV Report\n",
    "        csv_data.append({\n",
    "            'Existing_A': curr_fr,\n",
    "            'Existing_B': next_fr,\n",
    "            'Gap': gap,\n",
    "            'Middle_Frame': middle_fr if status == \"Middle Frame Added\" else \"N/A\",\n",
    "            'Status': status\n",
    "        })\n",
    "\n",
    "    # Don't forget the very last existing frame\n",
    "    if existing_frames:\n",
    "        extraction_list.append(existing_frames[-1])\n",
    "\n",
    "    # Remove duplicates just in case\n",
    "    extraction_list = sorted(list(set(extraction_list)))\n",
    "\n",
    "    # 4. Save CSV\n",
    "    csv_path = os.path.join(OUTPUT_ROOT, 'extraction_plan.csv')\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Plan saved to: {csv_path}\")\n",
    "    print(f\"Total frames to extract: {len(extraction_list)}\")\n",
    "    print(df.head()) # Show preview\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # 5. Get Video Metadata for Crop\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    cap.release()\n",
    "\n",
    "    x_start = width - MARGIN_RIGHT - CROP_SIZE\n",
    "    y_start = MARGIN_TOP\n",
    "    crop_params = (x_start, y_start)\n",
    "\n",
    "    # 6. Parallel Extraction\n",
    "    print(\"Starting extraction from VIDEO...\")\n",
    "    \n",
    "    num_cpus = cpu_count()\n",
    "    # Batch size: give each CPU a reasonable chunk of frames to process\n",
    "    chunk_size = int(np.ceil(len(extraction_list) / num_cpus))\n",
    "    if chunk_size < 1: chunk_size = 1\n",
    "\n",
    "    tasks = []\n",
    "    for i in range(0, len(extraction_list), chunk_size):\n",
    "        chunk = extraction_list[i : i + chunk_size]\n",
    "        tasks.append((VIDEO_PATH, chunk, (dir_orig, dir_crop), crop_params))\n",
    "\n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        with tqdm(total=len(extraction_list), unit=\"frame\") as pbar:\n",
    "            for count in pool.imap_unordered(extract_frames_worker, tasks):\n",
    "                pbar.update(count)\n",
    "\n",
    "    print(f\"\\nDone! CSV and images saved to: {OUTPUT_ROOT}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e49573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Info: 331751 frames | 29.999683531044475 FPS\n",
      "Generated 33176 frames based on 1/3s interval.\n",
      "Scanning existing frames in: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/euljiro_2nd/with_descending_ung_1120\n",
      "Found 3333 existing frames to preserve.\n",
      "----------------------------------------\n",
      "Plan saved to: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_plan_full_video.csv\n",
      "Total frames to extract: 36174\n",
      "----------------------------------------\n",
      "Preview (First 15 rows):\n",
      "    Frame_Number           Source  Timestamp_Sec\n",
      "0              0  New (1/3s Grid)           0.00\n",
      "1             10  New (1/3s Grid)           0.33\n",
      "2             20  New (1/3s Grid)           0.67\n",
      "3             30  New (1/3s Grid)           1.00\n",
      "4             40  New (1/3s Grid)           1.33\n",
      "5             50  New (1/3s Grid)           1.67\n",
      "6             60  New (1/3s Grid)           2.00\n",
      "7             70  New (1/3s Grid)           2.33\n",
      "8             80  New (1/3s Grid)           2.67\n",
      "9             90  New (1/3s Grid)           3.00\n",
      "10           100  New (1/3s Grid)           3.33\n",
      "11           110  New (1/3s Grid)           3.67\n",
      "12           120  New (1/3s Grid)           4.00\n",
      "13           130  New (1/3s Grid)           4.33\n",
      "14           140  New (1/3s Grid)           4.67\n",
      "----------------------------------------\n",
      "Preview (Around an existing frame):\n",
      "     Frame_Number                Source  Timestamp_Sec\n",
      "100           990       New (1/3s Grid)          33.00\n",
      "101          1000       New (1/3s Grid)          33.33\n",
      "102          1003  Existing (preserved)          33.43\n",
      "103          1010       New (1/3s Grid)          33.67\n",
      "104          1020       New (1/3s Grid)          34.00\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5132df29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning images in: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_10_frames/60_frames\n",
      "Found 5530 images to crop.\n",
      "Image Size: 1920x1080\n",
      "Crop Area: X[1480:1800], Y[0:320]\n",
      "Cropping with 8 CPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5530/5530 [00:47<00:00, 115.36img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Done! Cropped images saved to: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_10_frames/60_frames/cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SOURCE_DIR = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_10_frames/60_frames'\n",
    "DEST_DIR   = os.path.join(SOURCE_DIR, 'cropped')\n",
    "\n",
    "# Crop Config\n",
    "CROP_SIZE     = 320\n",
    "MARGIN_RIGHT  = 120\n",
    "MARGIN_TOP    = 0\n",
    "# ---------------------\n",
    "\n",
    "def crop_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function to read, crop, and save a single image.\n",
    "    args: (file_path, save_path, crop_coords)\n",
    "    \"\"\"\n",
    "    file_path, save_path, (x_start, y_start) = args\n",
    "    \n",
    "    img = cv2.imread(file_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    # Crop logic: img[y:y+h, x:x+w]\n",
    "    cropped = img[y_start : y_start + CROP_SIZE, \n",
    "                  x_start : x_start + CROP_SIZE]\n",
    "    \n",
    "    cv2.imwrite(save_path, cropped)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Folders\n",
    "    os.makedirs(DEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 2. Scan Files\n",
    "    print(f\"Scanning images in: {SOURCE_DIR}\")\n",
    "    files = glob.glob(os.path.join(SOURCE_DIR, \"*.jpg\"))\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Error: No images found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files)} images to crop.\")\n",
    "\n",
    "    # 3. Calculate Crop Coordinates (Based on first image)\n",
    "    # We need to read one image to get the width (for right margin calculation)\n",
    "    sample_img = cv2.imread(files[0])\n",
    "    if sample_img is None:\n",
    "        print(\"Error: Could not read the first image.\")\n",
    "        return\n",
    "\n",
    "    img_h, img_w = sample_img.shape[:2]\n",
    "    \n",
    "    # Calculate X Start (Width - Margin - CropSize)\n",
    "    x_start = img_w - MARGIN_RIGHT - CROP_SIZE\n",
    "    y_start = MARGIN_TOP\n",
    "    \n",
    "    print(f\"Image Size: {img_w}x{img_h}\")\n",
    "    print(f\"Crop Area: X[{x_start}:{x_start+CROP_SIZE}], Y[{y_start}:{y_start+CROP_SIZE}]\")\n",
    "\n",
    "    # 4. Prepare Parallel Tasks\n",
    "    tasks = []\n",
    "    for file_path in files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        save_path = os.path.join(DEST_DIR, filename)\n",
    "        tasks.append((file_path, save_path, (x_start, y_start)))\n",
    "\n",
    "    # 5. Execute\n",
    "    num_cpus = cpu_count()\n",
    "    print(f\"Cropping with {num_cpus} CPUs...\")\n",
    "    \n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        # Use imap to show progress bar\n",
    "        list(tqdm(pool.imap(crop_worker, tasks), total=len(tasks), unit=\"img\"))\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Done! Cropped images saved to: {DEST_DIR}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9d19b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files in: /home/holidayj/Downloads/train_arrival\n",
      "Found 3905 total files.\n",
      "Moving frames matching 'frame_number % 30 == 0'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3905/3905 [00:00<00:00, 66465.75file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Done! Moved 1226 images.\n",
      "Location: /home/holidayj/Downloads/train_arrival/30_frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SOURCE_DIR = '/home/holidayj/Downloads/train_arrival'\n",
    "DEST_DIR   = os.path.join(SOURCE_DIR, '30_frames')\n",
    "\n",
    "# Target Interval to Move\n",
    "# You have frames every 10 (0, 10, 20, 30...).\n",
    "# You want to move frames divisible by 30 (0, 30, 60...).\n",
    "TARGET_STEP = 30\n",
    "# ---------------------\n",
    "\n",
    "def parse_frame_number(filename):\n",
    "    \"\"\"\n",
    "    Extracts number from filename. \n",
    "    Example: 'euljiro_frame_000030.jpg' -> 30\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove extension\n",
    "        name_no_ext = os.path.splitext(filename)[0]\n",
    "        # Split by '_' and take the last part\n",
    "        num_str = name_no_ext.split('_')[-1]\n",
    "        return int(num_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # 1. Create Destination Folder\n",
    "    os.makedirs(DEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 2. Scan Files\n",
    "    print(f\"Scanning files in: {SOURCE_DIR}\")\n",
    "    # Assumes .jpg files. Change to *.png if needed.\n",
    "    files = glob.glob(os.path.join(SOURCE_DIR, \"*.jpg\"))\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Error: No images found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files)} total files.\")\n",
    "\n",
    "    # 3. Filter and Move\n",
    "    moved_count = 0\n",
    "    \n",
    "    print(f\"Moving frames matching 'frame_number % {TARGET_STEP} == 0'...\")\n",
    "    \n",
    "    for file_path in tqdm(files, unit=\"file\"):\n",
    "        filename = os.path.basename(file_path)\n",
    "        frame_num = parse_frame_number(filename)\n",
    "        \n",
    "        if frame_num is not None:\n",
    "            # Check if it is a \"30th\" frame (0, 30, 60, 90...)\n",
    "            if frame_num % TARGET_STEP == 0:\n",
    "                dest_path = os.path.join(DEST_DIR, filename)\n",
    "                shutil.move(file_path, dest_path)\n",
    "                moved_count += 1\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Done! Moved {moved_count} images.\")\n",
    "    print(f\"Location: {DEST_DIR}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83305a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files in: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_10_frames\n",
      "----------------------------------------\n",
      "First Frame: 0\n",
      "Last Frame:  331750\n",
      "Total Files: 36174\n",
      "----------------------------------------\n",
      "SUCCESS: No missing frames in the 10-frame grid.\n",
      "NOTE: Found 2998 EXTRA frames (not part of the regular interval).\n",
      "First 5 extras: [944, 1003, 1062, 1121, 1239]\n",
      "----------------------------------------\n",
      "Sorted file list saved to: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_10_frames/frame_analysis_report.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SOURCE_DIR = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/extraction_10_frames'\n",
    "OUTPUT_CSV = os.path.join(SOURCE_DIR, 'frame_analysis_report.csv')\n",
    "\n",
    "# Expected Grid Interval\n",
    "INTERVAL = 10\n",
    "# ---------------------\n",
    "\n",
    "def parse_frame_number(filename):\n",
    "    \"\"\"\n",
    "    Extracts 120 from 'euljiro_frame_000120.jpg' or 'euljiro_070001_frame_000120.jpg'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        name_no_ext = os.path.splitext(filename)[0]\n",
    "        # Always take the last segment after splitting by underscore\n",
    "        num_str = name_no_ext.split('_')[-1]\n",
    "        return int(num_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # 1. Scan Files\n",
    "    print(f\"Scanning files in: {SOURCE_DIR}\")\n",
    "    files = glob.glob(os.path.join(SOURCE_DIR, \"*.jpg\"))\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Error: No images found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Parse Data\n",
    "    data = []\n",
    "    frame_set = set()\n",
    "    \n",
    "    for f in files:\n",
    "        fname = os.path.basename(f)\n",
    "        fnum = parse_frame_number(fname)\n",
    "        \n",
    "        if fnum is not None:\n",
    "            data.append({'filename': fname, 'frame_number': fnum})\n",
    "            frame_set.add(fnum)\n",
    "    \n",
    "    # Sort by frame number\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(by='frame_number')\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"Error: Could not parse any frame numbers.\")\n",
    "        return\n",
    "\n",
    "    # 3. Analyze Range\n",
    "    min_frame = df['frame_number'].min()\n",
    "    max_frame = df['frame_number'].max()\n",
    "    total_files = len(df)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"First Frame: {min_frame}\")\n",
    "    print(f\"Last Frame:  {max_frame}\")\n",
    "    print(f\"Total Files: {total_files}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # 4. Check for Missing Frames (Based on 10-frame interval)\n",
    "    # We expect frames: min, min+10, min+20 ... max\n",
    "    # Note: We enforce the grid to start at 'min_frame' found.\n",
    "    expected_grid = set(range(min_frame, max_frame + 1, INTERVAL))\n",
    "    \n",
    "    # Missing = Expected - Existing\n",
    "    missing_frames = sorted(list(expected_grid - frame_set))\n",
    "    \n",
    "    if missing_frames:\n",
    "        print(f\"WARNING: Found {len(missing_frames)} MISSING frames in the 10-frame grid.\")\n",
    "        print(f\"First 5 missing: {missing_frames[:5]}\")\n",
    "        if len(missing_frames) > 5: print(\"...\")\n",
    "    else:\n",
    "        print(\"SUCCESS: No missing frames in the 10-frame grid.\")\n",
    "\n",
    "    # 5. Check for Extra Frames (Not in the 10-frame grid)\n",
    "    # Extras = Existing - Expected\n",
    "    # Note: This logic assumes 'min_frame' aligns with the grid. \n",
    "    # If min_frame is 3 and interval is 10, grid is 3, 13, 23...\n",
    "    extra_frames = sorted(list(frame_set - expected_grid))\n",
    "    \n",
    "    if extra_frames:\n",
    "        print(f\"NOTE: Found {len(extra_frames)} EXTRA frames (not part of the regular interval).\")\n",
    "        print(f\"First 5 extras: {extra_frames[:5]}\")\n",
    "    else:\n",
    "        print(\"NOTE: No extra frames found (Pure 10-frame dataset).\")\n",
    "\n",
    "    # 6. Save CSV\n",
    "    # We save the simple sorted list of files\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Sorted file list saved to: {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b16d4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files in: /media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival/cropped\n",
      "Found 4945 total images.\n",
      "Copying frames where 'frame_number % 30 == 0'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4945/4945 [00:01<00:00, 2729.88img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Done! Copied 1651 images.\n",
      "Target Folder: /media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival/cropped/60_frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# The folder you asked me to analyze in the previous turn\n",
    "SOURCE_DIR = '/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival/cropped'\n",
    "DEST_DIR   = os.path.join(SOURCE_DIR, '60_frames')\n",
    "\n",
    "# Target Interval: Copy only frames divisible by 60\n",
    "TARGET_STEP = 30\n",
    "# ---------------------\n",
    "\n",
    "def parse_frame_number(filename):\n",
    "    \"\"\"\n",
    "    Robustly extracts the frame number from filenames like:\n",
    "    - euljiro_frame_000120.jpg\n",
    "    - euljiro_070005_frame_000120.jpg\n",
    "    \"\"\"\n",
    "    try:\n",
    "        name_no_ext = os.path.splitext(filename)[0]\n",
    "        # Always take the last segment after splitting by underscore\n",
    "        num_str = name_no_ext.split('_')[-1]\n",
    "        return int(num_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Destination Folder\n",
    "    os.makedirs(DEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 2. Scan Files\n",
    "    print(f\"Scanning files in: {SOURCE_DIR}\")\n",
    "    files = glob.glob(os.path.join(SOURCE_DIR, \"*.jpg\"))\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Error: No images found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files)} total images.\")\n",
    "    print(f\"Copying frames where 'frame_number % {TARGET_STEP} == 0'...\")\n",
    "\n",
    "    # 3. Filter and Copy\n",
    "    copied_count = 0\n",
    "    \n",
    "    for file_path in tqdm(files, unit=\"img\"):\n",
    "        filename = os.path.basename(file_path)\n",
    "        frame_num = parse_frame_number(filename)\n",
    "        \n",
    "        if frame_num is not None:\n",
    "            # Check if it matches the 60-frame interval\n",
    "            if frame_num % TARGET_STEP == 0:\n",
    "                dest_path = os.path.join(DEST_DIR, filename)\n",
    "                \n",
    "                # copy2 preserves file metadata (timestamps)\n",
    "                shutil.copy2(file_path, dest_path)\n",
    "                copied_count += 1\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Done! Copied {copied_count} images.\")\n",
    "    print(f\"Target Folder: {DEST_DIR}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b798f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning: /media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/frames/chungmuro_hasun_10frame_1920_train_arrival/cropped_700/30_frames_crop/set_all_done\n",
      "------------------------------\n",
      "Process complete.\n",
      "Files copied: 1332 pairs\n",
      "Destination: /media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/frames/chungmuro_hasun_10frame_1920_train_arrival/cropped_700/30_frames_crop/set_all_done/valid_subset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def filter_yolo_dataset(source_dir, dest_subfolder_name=\"valid_subset\"):\n",
    "    source_path = Path(source_dir)\n",
    "    dest_path = source_path / dest_subfolder_name\n",
    "    \n",
    "    # Create destination directory if it doesn't exist\n",
    "    dest_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Image extensions to look for\n",
    "    valid_image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n",
    "    \n",
    "    count_copied = 0\n",
    "    \n",
    "    print(f\"Scanning: {source_path}\")\n",
    "    \n",
    "    # List all .txt files in the directory\n",
    "    txt_files = list(source_path.glob(\"*.txt\"))\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        # 1. Check if annotation file is valid (has at least one line)\n",
    "        has_annotation = False\n",
    "        try:\n",
    "            with open(txt_file, 'r') as f:\n",
    "                lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "                if len(lines) > 0:\n",
    "                    has_annotation = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {txt_file.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if not has_annotation:\n",
    "            continue\n",
    "            \n",
    "        # 2. Find matching image\n",
    "        base_name = txt_file.stem\n",
    "        image_found = None\n",
    "        \n",
    "        for ext in valid_image_extensions:\n",
    "            potential_img = source_path / (base_name + ext)\n",
    "            if potential_img.exists():\n",
    "                image_found = potential_img\n",
    "                break\n",
    "        \n",
    "        # 3. Copy both if image exists and annotation is valid\n",
    "        if image_found:\n",
    "            try:\n",
    "                shutil.copy2(txt_file, dest_path / txt_file.name)\n",
    "                shutil.copy2(image_found, dest_path / image_found.name)\n",
    "                count_copied += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {base_name}: {e}\")\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Process complete.\")\n",
    "    print(f\"Files copied: {count_copied} pairs\")\n",
    "    print(f\"Destination: {dest_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Your specific folder path\n",
    "    # folder_path = \"/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival/cropped/30_frames_kuni_20251227\"\n",
    "    folder_path = \"/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/frames/chungmuro_hasun_10frame_1920_train_arrival/cropped_700/30_frames_crop/set_all_done\"\n",
    "\n",
    "    filter_yolo_dataset(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87921940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1419 images. Checking intervals...\n",
      "\n",
      "--- Interval Analysis ---\n",
      "60     1098\n",
      "120     320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Most common interval: 60 frames\n",
      "Consistency: 77.43% of gaps are 60 frames.\n",
      "\n",
      "⚠️  WARNING: Mostly 60 frames, but some gaps exist (see table above).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define the path\n",
    "folder_path = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20251111_f0700_t1000/Ung_euljiro2025_inner_20260101/done'\n",
    "\n",
    "# 2. Get list of image files\n",
    "try:\n",
    "    files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif'))])\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The folder path does not exist:\\n{folder_path}\")\n",
    "    exit()\n",
    "\n",
    "if not files:\n",
    "    print(\"No image files found in the folder.\")\n",
    "else:\n",
    "    print(f\"Found {len(files)} images. Checking intervals...\")\n",
    "\n",
    "    # 3. Extract frame numbers from filenames\n",
    "    # Assumes format like \"image_000120.jpg\" where the last number is the frame\n",
    "    frame_numbers = []\n",
    "    for f in files:\n",
    "        # Regex: Find the last sequence of digits before the file extension\n",
    "        match = re.search(r'(\\d+)(?=\\.\\w+$)', f)\n",
    "        if match:\n",
    "            frame_numbers.append(int(match.group(1)))\n",
    "    \n",
    "    if len(frame_numbers) < 2:\n",
    "        print(\"Not enough images to calculate intervals.\")\n",
    "    else:\n",
    "        frame_numbers.sort()\n",
    "        \n",
    "        # 4. Calculate differences (intervals)\n",
    "        # diffs = [next - current]\n",
    "        diffs = [frame_numbers[i+1] - frame_numbers[i] for i in range(len(frame_numbers)-1)]\n",
    "        \n",
    "        # 5. Analyze results\n",
    "        diff_counts = pd.Series(diffs).value_counts().sort_index()\n",
    "        \n",
    "        print(\"\\n--- Interval Analysis ---\")\n",
    "        print(diff_counts)\n",
    "        \n",
    "        # Check specific condition\n",
    "        most_common_interval = diff_counts.idxmax()\n",
    "        consistency = (diff_counts.max() / len(diffs)) * 100\n",
    "        \n",
    "        print(f\"\\nMost common interval: {most_common_interval} frames\")\n",
    "        print(f\"Consistency: {consistency:.2f}% of gaps are {most_common_interval} frames.\")\n",
    "        \n",
    "        if most_common_interval == 60 and consistency == 100:\n",
    "            print(\"\\n✅ SUCCESS: All images are exactly 60 frames (2 seconds) apart.\")\n",
    "        elif most_common_interval == 60:\n",
    "            print(\"\\n⚠️  WARNING: Mostly 60 frames, but some gaps exist (see table above).\")\n",
    "        else:\n",
    "            print(f\"\\n❌ FAIL: The interval is not 60 frames. It appears to be {most_common_interval}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ce8378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created subfolder: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20251111_f0700_t1000/Ung_euljiro2025_inner_20260101/done/interval_120_gap\n",
      "Scanning 1419 files for 120-frame gaps...\n",
      "Moved Image: euljiro_073640_frame_066000.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073640_frame_066000.txt\n",
      "Moved Image: euljiro_073644_frame_066120.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073644_frame_066120.txt\n",
      "Moved Image: euljiro_073648_frame_066240.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073648_frame_066240.txt\n",
      "Moved Image: euljiro_073652_frame_066360.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073652_frame_066360.txt\n",
      "Moved Image: euljiro_073656_frame_066480.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073656_frame_066480.txt\n",
      "Moved Image: euljiro_073700_frame_066600.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073700_frame_066600.txt\n",
      "Moved Image: euljiro_073704_frame_066720.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073704_frame_066720.txt\n",
      "Moved Image: euljiro_073708_frame_066840.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073708_frame_066840.txt\n",
      "Moved Image: euljiro_073712_frame_066960.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073712_frame_066960.txt\n",
      "Moved Image: euljiro_073716_frame_067080.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073716_frame_067080.txt\n",
      "Moved Image: euljiro_073720_frame_067200.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073720_frame_067200.txt\n",
      "Moved Image: euljiro_073724_frame_067320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073724_frame_067320.txt\n",
      "Moved Image: euljiro_073728_frame_067440.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073728_frame_067440.txt\n",
      "Moved Image: euljiro_073732_frame_067560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073732_frame_067560.txt\n",
      "Moved Image: euljiro_073736_frame_067680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073736_frame_067680.txt\n",
      "Moved Image: euljiro_073740_frame_067800.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073744_frame_067920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073744_frame_067920.txt\n",
      "Moved Image: euljiro_073748_frame_068040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073748_frame_068040.txt\n",
      "Moved Image: euljiro_073752_frame_068160.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073756_frame_068280.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073800_frame_068400.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073804_frame_068520.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073808_frame_068640.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073812_frame_068760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073816_frame_068880.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073820_frame_069000.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073824_frame_069120.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073828_frame_069240.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073832_frame_069360.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073836_frame_069480.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073840_frame_069600.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073844_frame_069720.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073848_frame_069840.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073852_frame_069960.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073856_frame_070080.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073900_frame_070200.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073904_frame_070320.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073908_frame_070440.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073912_frame_070560.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073916_frame_070680.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073920_frame_070800.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073924_frame_070920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073924_frame_070920.txt\n",
      "Moved Image: euljiro_073928_frame_071040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073928_frame_071040.txt\n",
      "Moved Image: euljiro_073932_frame_071160.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_073932_frame_071160.txt\n",
      "Moved Image: euljiro_073936_frame_071280.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073940_frame_071400.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073944_frame_071520.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073948_frame_071640.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073952_frame_071760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_073956_frame_071880.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074000_frame_072000.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074004_frame_072120.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074008_frame_072240.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074012_frame_072360.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074016_frame_072480.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074020_frame_072600.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074024_frame_072720.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074028_frame_072840.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074032_frame_072960.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074036_frame_073080.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074040_frame_073200.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074040_frame_073200.txt\n",
      "Moved Image: euljiro_074044_frame_073320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074044_frame_073320.txt\n",
      "Moved Image: euljiro_074048_frame_073440.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074048_frame_073440.txt\n",
      "Moved Image: euljiro_074052_frame_073560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074052_frame_073560.txt\n",
      "Moved Image: euljiro_074056_frame_073680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074056_frame_073680.txt\n",
      "Moved Image: euljiro_074100_frame_073800.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074100_frame_073800.txt\n",
      "Moved Image: euljiro_074104_frame_073920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074104_frame_073920.txt\n",
      "Moved Image: euljiro_074108_frame_074040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074108_frame_074040.txt\n",
      "Moved Image: euljiro_074112_frame_074160.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074112_frame_074160.txt\n",
      "Moved Image: euljiro_074116_frame_074280.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074116_frame_074280.txt\n",
      "Moved Image: euljiro_074120_frame_074400.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074120_frame_074400.txt\n",
      "Moved Image: euljiro_074124_frame_074520.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074124_frame_074520.txt\n",
      "Moved Image: euljiro_074128_frame_074640.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074132_frame_074760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074136_frame_074880.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074140_frame_075000.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074144_frame_075120.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074148_frame_075240.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074148_frame_075240.txt\n",
      "Moved Image: euljiro_074152_frame_075360.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074152_frame_075360.txt\n",
      "Moved Image: euljiro_074156_frame_075480.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074156_frame_075480.txt\n",
      "Moved Image: euljiro_074200_frame_075600.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074200_frame_075600.txt\n",
      "Moved Image: euljiro_074204_frame_075720.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074204_frame_075720.txt\n",
      "Moved Image: euljiro_074208_frame_075840.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074208_frame_075840.txt\n",
      "Moved Image: euljiro_074212_frame_075960.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074212_frame_075960.txt\n",
      "Moved Image: euljiro_074216_frame_076080.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074216_frame_076080.txt\n",
      "Moved Image: euljiro_074220_frame_076200.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074220_frame_076200.txt\n",
      "Moved Image: euljiro_074224_frame_076320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074224_frame_076320.txt\n",
      "Moved Image: euljiro_074228_frame_076440.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074228_frame_076440.txt\n",
      "Moved Image: euljiro_074232_frame_076560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074232_frame_076560.txt\n",
      "Moved Image: euljiro_074236_frame_076680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074236_frame_076680.txt\n",
      "Moved Image: euljiro_074240_frame_076800.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074240_frame_076800.txt\n",
      "Moved Image: euljiro_074244_frame_076920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074244_frame_076920.txt\n",
      "Moved Image: euljiro_074248_frame_077040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074248_frame_077040.txt\n",
      "Moved Image: euljiro_074252_frame_077160.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074252_frame_077160.txt\n",
      "Moved Image: euljiro_074256_frame_077280.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074256_frame_077280.txt\n",
      "Moved Image: euljiro_074300_frame_077400.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074300_frame_077400.txt\n",
      "Moved Image: euljiro_074304_frame_077520.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074304_frame_077520.txt\n",
      "Moved Image: euljiro_074308_frame_077640.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074308_frame_077640.txt\n",
      "Moved Image: euljiro_074312_frame_077760.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074312_frame_077760.txt\n",
      "Moved Image: euljiro_074316_frame_077880.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074316_frame_077880.txt\n",
      "Moved Image: euljiro_074320_frame_078000.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074320_frame_078000.txt\n",
      "Moved Image: euljiro_074324_frame_078120.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074324_frame_078120.txt\n",
      "Moved Image: euljiro_074328_frame_078240.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074328_frame_078240.txt\n",
      "Moved Image: euljiro_074332_frame_078360.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074332_frame_078360.txt\n",
      "Moved Image: euljiro_074336_frame_078480.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074336_frame_078480.txt\n",
      "Moved Image: euljiro_074340_frame_078600.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074344_frame_078720.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074344_frame_078720.txt\n",
      "Moved Image: euljiro_074348_frame_078840.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074348_frame_078840.txt\n",
      "Moved Image: euljiro_074352_frame_078960.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074352_frame_078960.txt\n",
      "Moved Image: euljiro_074356_frame_079080.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074356_frame_079080.txt\n",
      "Moved Image: euljiro_074400_frame_079200.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074400_frame_079200.txt\n",
      "Moved Image: euljiro_074404_frame_079320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074404_frame_079320.txt\n",
      "Moved Image: euljiro_074408_frame_079440.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074408_frame_079440.txt\n",
      "Moved Image: euljiro_074412_frame_079560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074412_frame_079560.txt\n",
      "Moved Image: euljiro_074416_frame_079680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074416_frame_079680.txt\n",
      "Moved Image: euljiro_074420_frame_079800.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074420_frame_079800.txt\n",
      "Moved Image: euljiro_074424_frame_079920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074424_frame_079920.txt\n",
      "Moved Image: euljiro_074428_frame_080040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074428_frame_080040.txt\n",
      "Moved Image: euljiro_074432_frame_080160.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074432_frame_080160.txt\n",
      "Moved Image: euljiro_074436_frame_080280.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074436_frame_080280.txt\n",
      "Moved Image: euljiro_074440_frame_080400.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074440_frame_080400.txt\n",
      "Moved Image: euljiro_074444_frame_080520.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074448_frame_080640.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074452_frame_080760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074456_frame_080880.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074500_frame_081000.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074504_frame_081120.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074508_frame_081240.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074512_frame_081360.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074516_frame_081480.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074520_frame_081600.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074524_frame_081720.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074528_frame_081840.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074532_frame_081960.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074536_frame_082080.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074540_frame_082200.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074544_frame_082320.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074548_frame_082440.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074552_frame_082560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074552_frame_082560.txt\n",
      "Moved Image: euljiro_074556_frame_082680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074556_frame_082680.txt\n",
      "Moved Image: euljiro_074600_frame_082800.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074604_frame_082920.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074608_frame_083040.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074612_frame_083160.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074616_frame_083280.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074620_frame_083400.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074624_frame_083520.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074628_frame_083640.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074632_frame_083760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074636_frame_083880.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074636_frame_083880.txt\n",
      "Moved Image: euljiro_074640_frame_084000.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074640_frame_084000.txt\n",
      "Moved Image: euljiro_074644_frame_084120.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074648_frame_084240.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074652_frame_084360.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074656_frame_084480.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074700_frame_084600.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074700_frame_084600.txt\n",
      "Moved Image: euljiro_074704_frame_084720.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074704_frame_084720.txt\n",
      "Moved Image: euljiro_074708_frame_084840.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074708_frame_084840.txt\n",
      "Moved Image: euljiro_074712_frame_084960.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074712_frame_084960.txt\n",
      "Moved Image: euljiro_074716_frame_085080.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074716_frame_085080.txt\n",
      "Moved Image: euljiro_074720_frame_085200.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074720_frame_085200.txt\n",
      "Moved Image: euljiro_074724_frame_085320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074724_frame_085320.txt\n",
      "Moved Image: euljiro_074728_frame_085440.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074728_frame_085440.txt\n",
      "Moved Image: euljiro_074732_frame_085560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074732_frame_085560.txt\n",
      "Moved Image: euljiro_074736_frame_085680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074736_frame_085680.txt\n",
      "Moved Image: euljiro_074740_frame_085800.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074740_frame_085800.txt\n",
      "Moved Image: euljiro_074744_frame_085920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074744_frame_085920.txt\n",
      "Moved Image: euljiro_074748_frame_086040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074748_frame_086040.txt\n",
      "Moved Image: euljiro_074752_frame_086160.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074752_frame_086160.txt\n",
      "Moved Image: euljiro_074756_frame_086280.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074756_frame_086280.txt\n",
      "Moved Image: euljiro_074800_frame_086400.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074800_frame_086400.txt\n",
      "Moved Image: euljiro_074804_frame_086520.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074804_frame_086520.txt\n",
      "Moved Image: euljiro_074808_frame_086640.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074812_frame_086760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074816_frame_086880.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074820_frame_087000.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074824_frame_087120.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074824_frame_087120.txt\n",
      "Moved Image: euljiro_074828_frame_087240.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074828_frame_087240.txt\n",
      "Moved Image: euljiro_074832_frame_087360.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074836_frame_087480.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074840_frame_087600.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074844_frame_087720.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074848_frame_087840.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074852_frame_087960.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074856_frame_088080.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074900_frame_088200.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074904_frame_088320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074904_frame_088320.txt\n",
      "Moved Image: euljiro_074908_frame_088440.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074908_frame_088440.txt\n",
      "Moved Image: euljiro_074912_frame_088560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074912_frame_088560.txt\n",
      "Moved Image: euljiro_074916_frame_088680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074916_frame_088680.txt\n",
      "Moved Image: euljiro_074920_frame_088800.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074920_frame_088800.txt\n",
      "Moved Image: euljiro_074924_frame_088920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074924_frame_088920.txt\n",
      "Moved Image: euljiro_074928_frame_089040.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074932_frame_089160.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074936_frame_089280.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074940_frame_089400.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074944_frame_089520.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074944_frame_089520.txt\n",
      "Moved Image: euljiro_074948_frame_089640.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074948_frame_089640.txt\n",
      "Moved Image: euljiro_074952_frame_089760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_074956_frame_089880.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_074956_frame_089880.txt\n",
      "Moved Image: euljiro_075000_frame_090000.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075000_frame_090000.txt\n",
      "Moved Image: euljiro_075004_frame_090120.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075008_frame_090240.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075012_frame_090360.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075016_frame_090480.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075020_frame_090600.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075024_frame_090720.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075028_frame_090840.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075032_frame_090960.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075036_frame_091080.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075036_frame_091080.txt\n",
      "Moved Image: euljiro_075040_frame_091200.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075040_frame_091200.txt\n",
      "Moved Image: euljiro_075044_frame_091320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075044_frame_091320.txt\n",
      "Moved Image: euljiro_075048_frame_091440.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075048_frame_091440.txt\n",
      "Moved Image: euljiro_075052_frame_091560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075052_frame_091560.txt\n",
      "Moved Image: euljiro_075056_frame_091680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075056_frame_091680.txt\n",
      "Moved Image: euljiro_075100_frame_091800.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075100_frame_091800.txt\n",
      "Moved Image: euljiro_075104_frame_091920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075104_frame_091920.txt\n",
      "Moved Image: euljiro_075108_frame_092040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075108_frame_092040.txt\n",
      "Moved Image: euljiro_075112_frame_092160.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075112_frame_092160.txt\n",
      "Moved Image: euljiro_075116_frame_092280.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075116_frame_092280.txt\n",
      "Moved Image: euljiro_075120_frame_092400.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075120_frame_092400.txt\n",
      "Moved Image: euljiro_075124_frame_092520.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075124_frame_092520.txt\n",
      "Moved Image: euljiro_075128_frame_092640.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075128_frame_092640.txt\n",
      "Moved Image: euljiro_075132_frame_092760.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075132_frame_092760.txt\n",
      "Moved Image: euljiro_075136_frame_092880.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075136_frame_092880.txt\n",
      "Moved Image: euljiro_075140_frame_093000.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075140_frame_093000.txt\n",
      "Moved Image: euljiro_075144_frame_093120.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075144_frame_093120.txt\n",
      "Moved Image: euljiro_075148_frame_093240.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075148_frame_093240.txt\n",
      "Moved Image: euljiro_075152_frame_093360.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075152_frame_093360.txt\n",
      "Moved Image: euljiro_075156_frame_093480.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075156_frame_093480.txt\n",
      "Moved Image: euljiro_075200_frame_093600.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075204_frame_093720.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075208_frame_093840.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075212_frame_093960.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075216_frame_094080.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075216_frame_094080.txt\n",
      "Moved Image: euljiro_075220_frame_094200.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075220_frame_094200.txt\n",
      "Moved Image: euljiro_075224_frame_094320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075224_frame_094320.txt\n",
      "Moved Image: euljiro_075228_frame_094440.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075232_frame_094560.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075236_frame_094680.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075240_frame_094800.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075244_frame_094920.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075248_frame_095040.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075252_frame_095160.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075256_frame_095280.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075300_frame_095400.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075304_frame_095520.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075308_frame_095640.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075312_frame_095760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075316_frame_095880.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075320_frame_096000.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075324_frame_096120.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075328_frame_096240.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075332_frame_096360.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075336_frame_096480.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075340_frame_096600.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075340_frame_096600.txt\n",
      "Moved Image: euljiro_075344_frame_096720.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075344_frame_096720.txt\n",
      "Moved Image: euljiro_075348_frame_096840.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075348_frame_096840.txt\n",
      "Moved Image: euljiro_075352_frame_096960.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075352_frame_096960.txt\n",
      "Moved Image: euljiro_075356_frame_097080.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075356_frame_097080.txt\n",
      "Moved Image: euljiro_075400_frame_097200.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075400_frame_097200.txt\n",
      "Moved Image: euljiro_075404_frame_097320.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075404_frame_097320.txt\n",
      "Moved Image: euljiro_075408_frame_097440.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075408_frame_097440.txt\n",
      "Moved Image: euljiro_075412_frame_097560.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075412_frame_097560.txt\n",
      "Moved Image: euljiro_075416_frame_097680.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075416_frame_097680.txt\n",
      "Moved Image: euljiro_075420_frame_097800.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075420_frame_097800.txt\n",
      "Moved Image: euljiro_075424_frame_097920.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075424_frame_097920.txt\n",
      "Moved Image: euljiro_075428_frame_098040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075428_frame_098040.txt\n",
      "Moved Image: euljiro_075432_frame_098160.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075432_frame_098160.txt\n",
      "Moved Image: euljiro_075436_frame_098280.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075436_frame_098280.txt\n",
      "Moved Image: euljiro_075440_frame_098400.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075440_frame_098400.txt\n",
      "Moved Image: euljiro_075444_frame_098520.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075444_frame_098520.txt\n",
      "Moved Image: euljiro_075448_frame_098640.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075448_frame_098640.txt\n",
      "Moved Image: euljiro_075452_frame_098760.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075452_frame_098760.txt\n",
      "Moved Image: euljiro_075456_frame_098880.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075456_frame_098880.txt\n",
      "Moved Image: euljiro_075500_frame_099000.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075500_frame_099000.txt\n",
      "Moved Image: euljiro_075504_frame_099120.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075504_frame_099120.txt\n",
      "Moved Image: euljiro_075508_frame_099240.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075508_frame_099240.txt\n",
      "Moved Image: euljiro_075512_frame_099360.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075512_frame_099360.txt\n",
      "Moved Image: euljiro_075516_frame_099480.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075520_frame_099600.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075524_frame_099720.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075528_frame_099840.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075532_frame_099960.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075536_frame_100080.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075540_frame_100200.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075544_frame_100320.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075548_frame_100440.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075552_frame_100560.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075556_frame_100680.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075600_frame_100800.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075604_frame_100920.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075608_frame_101040.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075612_frame_101160.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075616_frame_101280.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075620_frame_101400.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075624_frame_101520.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075628_frame_101640.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075632_frame_101760.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075636_frame_101880.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075640_frame_102000.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075644_frame_102120.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075648_frame_102240.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075652_frame_102360.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075656_frame_102480.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075656_frame_102480.txt\n",
      "Moved Image: euljiro_075700_frame_102600.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075700_frame_102600.txt\n",
      "Moved Image: euljiro_075704_frame_102720.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075704_frame_102720.txt\n",
      "Moved Image: euljiro_075708_frame_102840.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075708_frame_102840.txt\n",
      "Moved Image: euljiro_075712_frame_102960.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075716_frame_103080.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075720_frame_103200.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075724_frame_103320.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075728_frame_103440.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075732_frame_103560.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075736_frame_103680.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075740_frame_103800.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075744_frame_103920.jpg (Gap: 120)\n",
      "Moved Image: euljiro_075748_frame_104040.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075748_frame_104040.txt\n",
      "Moved Image: euljiro_075752_frame_104160.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075752_frame_104160.txt\n",
      "Moved Image: euljiro_075756_frame_104280.jpg (Gap: 120)\n",
      "   Moved Txt: euljiro_075756_frame_104280.txt\n",
      "\n",
      "Operation Complete.\n",
      "Total files moved: 320\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# 1. Define the path (Update if needed)\n",
    "folder_path = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20251111_f0700_t1000/Ung_euljiro2025_inner_20260101/done'\n",
    "target_subfolder = 'interval_120_gap'\n",
    "\n",
    "# 2. Create the subfolder if it doesn't exist\n",
    "destination_path = os.path.join(folder_path, target_subfolder)\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "    print(f\"Created subfolder: {destination_path}\")\n",
    "\n",
    "# 3. Get and sort list of image files\n",
    "# Extensions to check\n",
    "img_extensions = ('.jpg', '.png', '.jpeg', '.bmp', '.tif')\n",
    "files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(img_extensions)])\n",
    "\n",
    "if not files:\n",
    "    print(\"No image files found.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Scanning {len(files)} files for 120-frame gaps...\")\n",
    "\n",
    "moved_count = 0\n",
    "frame_map = [] # List of tuples: (frame_number, filename)\n",
    "\n",
    "# 4. Extract frame numbers\n",
    "for f in files:\n",
    "    match = re.search(r'(\\d+)(?=\\.\\w+$)', f)\n",
    "    if match:\n",
    "        frame_map.append((int(match.group(1)), f))\n",
    "\n",
    "# Sort by frame number ensures correct interval calculation\n",
    "frame_map.sort(key=lambda x: x[0])\n",
    "\n",
    "# 5. Iterate and Move\n",
    "# We start from index 1 because we need to compare with the previous file\n",
    "for i in range(1, len(frame_map)):\n",
    "    current_frame, current_file = frame_map[i]\n",
    "    prev_frame, prev_file = frame_map[i-1]\n",
    "    \n",
    "    interval = current_frame - prev_frame\n",
    "    \n",
    "    if interval == 120:\n",
    "        # This current file is 120 frames away from the previous one\n",
    "        # Move Image\n",
    "        src_img = os.path.join(folder_path, current_file)\n",
    "        dst_img = os.path.join(destination_path, current_file)\n",
    "        \n",
    "        try:\n",
    "            shutil.move(src_img, dst_img)\n",
    "            print(f\"Moved Image: {current_file} (Gap: {interval})\")\n",
    "            \n",
    "            # Move corresponding Text file\n",
    "            # Assuming txt has same name but .txt extension\n",
    "            base_name = os.path.splitext(current_file)[0]\n",
    "            txt_file = base_name + \".txt\"\n",
    "            src_txt = os.path.join(folder_path, txt_file)\n",
    "            dst_txt = os.path.join(destination_path, txt_file)\n",
    "            \n",
    "            if os.path.exists(src_txt):\n",
    "                shutil.move(src_txt, dst_txt)\n",
    "                print(f\"   Moved Txt: {txt_file}\")\n",
    "            \n",
    "            moved_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error moving {current_file}: {e}\")\n",
    "\n",
    "print(f\"\\nOperation Complete.\")\n",
    "print(f\"Total files moved: {moved_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07471da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created subfolder: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20251111_f0700_t1000/Ung_euljiro2025_inner_20260101/done/frames_multiple_of_120\n",
      "Scanning 1099 files...\n",
      "\n",
      "Operation Complete.\n",
      "Total files moved: 550\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# 1. Define paths\n",
    "folder_path = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20251111_f0700_t1000/Ung_euljiro2025_inner_20260101/done'\n",
    "target_subfolder = 'frames_multiple_of_120'\n",
    "\n",
    "# 2. Create destination folder\n",
    "destination_path = os.path.join(folder_path, target_subfolder)\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "    print(f\"Created subfolder: {destination_path}\")\n",
    "\n",
    "# 3. List images\n",
    "img_extensions = ('.jpg', '.png', '.jpeg', '.bmp', '.tif')\n",
    "files = [f for f in os.listdir(folder_path) if f.lower().endswith(img_extensions)]\n",
    "\n",
    "print(f\"Scanning {len(files)} files...\")\n",
    "\n",
    "moved_count = 0\n",
    "\n",
    "for filename in files:\n",
    "    # Extract frame number (looks for last digits in filename)\n",
    "    # e.g., \"euljiro_070002_frame_000060.jpg\" -> 60\n",
    "    match = re.search(r'(\\d+)(?=\\.\\w+$)', filename)\n",
    "    \n",
    "    if match:\n",
    "        frame_number = int(match.group(1))\n",
    "        \n",
    "        # CHECK: Is this frame number a multiple of 120? (0, 120, 240...)\n",
    "        if frame_number % 120 == 0:\n",
    "            \n",
    "            # Move Image\n",
    "            src_img = os.path.join(folder_path, filename)\n",
    "            dst_img = os.path.join(destination_path, filename)\n",
    "            \n",
    "            try:\n",
    "                shutil.move(src_img, dst_img)\n",
    "                # print(f\"Moved: {filename}\") # Uncomment to see every move\n",
    "                \n",
    "                # Move corresponding Text file if it exists\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                txt_file = base_name + \".txt\"\n",
    "                src_txt = os.path.join(folder_path, txt_file)\n",
    "                dst_txt = os.path.join(destination_path, txt_file)\n",
    "                \n",
    "                if os.path.exists(src_txt):\n",
    "                    shutil.move(src_txt, dst_txt)\n",
    "                \n",
    "                moved_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error moving {filename}: {e}\")\n",
    "\n",
    "print(f\"\\nOperation Complete.\")\n",
    "print(f\"Total files moved: {moved_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362bc68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Saved to: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/temp/cropped_euljiro_frame_132000.jpg\n",
      "Crop Area: x[1480:1800], y[0:320]\n"
     ]
    }
   ],
   "source": [
    "# Crop 을지로\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "file_path = \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/temp/euljiro_frame_132000.jpg\"\n",
    "CROP_SIZE = 320\n",
    "MARGIN_RIGHT = 120\n",
    "MARGIN_TOP = 0\n",
    "\n",
    "# --- Load Image ---\n",
    "img = cv2.imread(file_path)\n",
    "\n",
    "if img is None:\n",
    "    print(f\"Error: Image not found at {file_path}\")\n",
    "else:\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    # --- Calculate Coordinates ---\n",
    "    # X coordinates (Horizontal)\n",
    "    x_end = w - MARGIN_RIGHT\n",
    "    x_start = x_end - CROP_SIZE\n",
    "    \n",
    "    # Y coordinates (Vertical)\n",
    "    y_start = MARGIN_TOP\n",
    "    y_end = y_start + CROP_SIZE\n",
    "\n",
    "    # --- Perform Crop ---\n",
    "    # Ensure coordinates are within image bounds\n",
    "    if x_start < 0 or y_end > h:\n",
    "        print(\"Warning: Crop region exceeds image dimensions.\")\n",
    "    \n",
    "    crop_img = img[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    # --- Save ---\n",
    "    # Saves to the same directory with a prefix\n",
    "    dir_name = os.path.dirname(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    save_path = os.path.join(dir_name, f\"cropped_{file_name}\")\n",
    "    \n",
    "    cv2.imwrite(save_path, crop_img)\n",
    "    print(f\"Success! Saved to: {save_path}\")\n",
    "    print(f\"Crop Area: x[{x_start}:{x_end}], y[{y_start}:{y_end}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
