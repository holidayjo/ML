{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14748107",
   "metadata": {},
   "source": [
    "## From video, we can check the crop image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ae3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/holidayj/Documents/github/ML/Python/annotation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.video_utils import extract_frames_fast\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "VIDEO_PATH    = '/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/chungmuro_hasun_20221019T172940_20221019T203040.mp4'\n",
    "OUTPUT_FOLDER = 'frames/chungmuro_hasun_20221019_f1729_t2030_1frame_700'\n",
    "\n",
    "INTERVAL_SEC  = 1/3   # Extract 3 frames per second (approx)\n",
    "CROP_SIZE     = 700\n",
    "MARGIN_RIGHT  = 400\n",
    "MARGIN_TOP    = 30\n",
    "FILE_PREFIX   = \"chungmuro_frame\"\n",
    "\n",
    "def main():\n",
    "    extract_frames_fast(\n",
    "        video_path=VIDEO_PATH,\n",
    "        output_folder=OUTPUT_FOLDER,\n",
    "        interval_sec=INTERVAL_SEC,\n",
    "        crop_size=CROP_SIZE,\n",
    "        margin_right=MARGIN_RIGHT,\n",
    "        margin_top=MARGIN_TOP,\n",
    "        file_prefix=FILE_PREFIX\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7bd13",
   "metadata": {},
   "source": [
    "## From hd images, crop images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af8d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing 4161 Images ---\n",
      "Original Size: 1920x1080\n",
      "Crop: 700x700 at (820, 30)\n",
      "Using 7 background processes for saving.\n",
      "Starting batch crop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4161/4161 [02:11<00:00, 31.58img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing finished. Waiting for file writes to complete...\n",
      "Done! Saved 4161 images to './cropped_images_700'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "SOURCE_FOLDER = \"/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/frames/chungmuro_hasun_10frame_1920_train_arrival\"\n",
    "OUTPUT_FOLDER = \"./cropped_images_700\"\n",
    "\n",
    "# Crop Parameters\n",
    "CROP_SIZE = 700\n",
    "MARGIN_RIGHT = 400\n",
    "MARGIN_TOP = 30\n",
    "\n",
    "def save_image_worker(args):\n",
    "    \"\"\"\n",
    "    Independent worker function to save the image.\n",
    "    (Reused from utils/video_utils.py pattern)\n",
    "    \"\"\"\n",
    "    img_data, save_path = args\n",
    "    cv2.imwrite(save_path, img_data)\n",
    "\n",
    "def process_existing_images(source_folder, output_folder, crop_size, margin_right, margin_top):\n",
    "    # 1. Setup\n",
    "    if not os.path.exists(source_folder):\n",
    "        print(f\"Error: Source folder not found at {source_folder}\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get list of images (assuming .jpg, add .png if needed)\n",
    "    image_paths = sorted(glob.glob(os.path.join(source_folder, \"*.jpg\")))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(\"No .jpg images found in source folder.\")\n",
    "        return\n",
    "\n",
    "    # 2. Calculate Crop Coordinates based on the first image\n",
    "    first_img = cv2.imread(image_paths[0])\n",
    "    if first_img is None:\n",
    "        print(\"Error reading the first image.\")\n",
    "        return\n",
    "\n",
    "    h, width, _ = first_img.shape\n",
    "    \n",
    "    # Logic: x_start = width - margin_right - crop_size\n",
    "    x_start = width - margin_right - crop_size\n",
    "    y_start = margin_top\n",
    "    \n",
    "    # Boundary checks\n",
    "    if x_start < 0: x_start = 0\n",
    "    if y_start < 0: y_start = 0\n",
    "\n",
    "    print(f\"--- Processing {len(image_paths)} Images ---\")\n",
    "    print(f\"Original Size: {width}x{h}\")\n",
    "    print(f\"Crop: {crop_size}x{crop_size} at ({x_start}, {y_start})\")\n",
    "    \n",
    "    # 3. Initialize Worker Pool\n",
    "    worker_count = max(1, cpu_count() - 1)\n",
    "    print(f\"Using {worker_count} background processes for saving.\")\n",
    "    \n",
    "    pool = Pool(processes=worker_count)\n",
    "    saved_count = 0\n",
    "\n",
    "    # 4. Processing Loop\n",
    "    print(\"Starting batch crop...\")\n",
    "    \n",
    "    for img_path in tqdm(image_paths, unit=\"img\"):\n",
    "        # Read image in main process\n",
    "        frame = cv2.imread(img_path)\n",
    "        \n",
    "        if frame is None:\n",
    "            continue\n",
    "\n",
    "        # Crop Logic\n",
    "        cropped = frame[y_start : y_start + crop_size, \n",
    "                        x_start : x_start + crop_size]\n",
    "        \n",
    "        # Construct filename (keep original name)\n",
    "        filename = os.path.basename(img_path)\n",
    "        save_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # Async Save\n",
    "        pool.apply_async(save_image_worker, args=((cropped, save_path),))\n",
    "        saved_count += 1\n",
    "\n",
    "    # 5. Cleanup\n",
    "    print(\"\\nProcessing finished. Waiting for file writes to complete...\")\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(f\"Done! Saved {saved_count} images to '{output_folder}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_existing_images(SOURCE_FOLDER, OUTPUT_FOLDER, CROP_SIZE, MARGIN_RIGHT, MARGIN_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701e0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning reference directory...\n",
      "Found 4161 images in Source.\n",
      "Found 2769 files in Reference.\n",
      "Starting copy process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4161 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4161/4161 [00:00<00:00, 4760.19file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary ---\n",
      "Total processed: 4161\n",
      "Copied to TEMP1 (Matched): 1384\n",
      "Copied to TEMP2 (Rest):    2777\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7be7b3e",
   "metadata": {},
   "source": [
    "## Saving 1 frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9968de",
   "metadata": {},
   "source": [
    "## Finding Cropping area from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1fbf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for a valid Keyframe...\n",
      "Success: Valid frame found at index 1\n",
      "Original Resolution: 1920x1080\n",
      "Cropping Area -> X: 1280 to 1920, Y: 0 to 640\n",
      "Saved cropped image to: output_frames/cropped_700.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x3a1d3240] missing picture in access unit with size 40\n",
      "[h264 @ 0x3a1d3240] no frame!\n",
      "[h264 @ 0x3a0c2180] no frame!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "video_path      = '/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_20221019T172940-20221019T202940.mp4'\n",
    "output_folder   = 'output_frames'\n",
    "output_filename = 'cropped_700.jpg'\n",
    "# crop_size       = 600\n",
    "crop_size       = 700\n",
    "\n",
    "# Cropping Margins\n",
    "margin_top   = 30    # Move down pixels from the top edge\n",
    "margin_right = 400  # Move left 120 pixels from the right edge\n",
    "# ---------------------\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video at {video_path}\")\n",
    "else:\n",
    "    # 1. Search for the first valid frame (Fix for the [h264] error)\n",
    "    frame_found = False\n",
    "    max_attempts = 100\n",
    "    \n",
    "    print(\"Searching for a valid Keyframe...\")\n",
    "    \n",
    "    for i in range(max_attempts):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            print(f\"Success: Valid frame found at index {i}\")\n",
    "            \n",
    "            # --- CROP LOGIC STARTS HERE ---\n",
    "            \n",
    "            # 2. Get Dimensions\n",
    "            height, width, _ = frame.shape\n",
    "            \n",
    "            # 3. Calculate Coordinates\n",
    "            # Y: Start at top margin\n",
    "            y_start = margin_top\n",
    "            y_end = y_start + crop_size\n",
    "\n",
    "            # X: Start from right side (width) - margin - crop_size\n",
    "            x_end = width - margin_right\n",
    "            x_start = x_end - crop_size\n",
    "\n",
    "            print(f\"Original Resolution: {width}x{height}\")\n",
    "            print(f\"Cropping Area -> X: {x_start} to {x_end}, Y: {y_start} to {y_end}\")\n",
    "\n",
    "            # 4. Perform Crop\n",
    "            cropped_frame = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            # 5. Save\n",
    "            full_save_path = os.path.join(output_folder, output_filename)\n",
    "            cv2.imwrite(full_save_path, cropped_frame)\n",
    "            print(f\"Saved cropped image to: {full_save_path}\")\n",
    "            \n",
    "            frame_found = True\n",
    "            break # Stop after saving the first valid frame\n",
    "            \n",
    "            # --- CROP LOGIC ENDS HERE ---\n",
    "\n",
    "    if not frame_found:\n",
    "        print(\"Error: Could not find any valid frames in the beginning of the video.\")\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4daee6",
   "metadata": {},
   "source": [
    "# Cropping area from the full frame images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285ac949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4945 images. Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4945/4945 [02:52<00:00, 28.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! 4945 images saved to:\n",
      "/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival/cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm  # Optional: for a progress bar, run 'pip install tqdm' if missing\n",
    "\n",
    "# 1. Configuration\n",
    "source_dir = \"/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival\"\n",
    "output_dir = os.path.join(source_dir, \"cropped\")\n",
    "CROP_W, CROP_H = 640, 640\n",
    "\n",
    "# 2. Setup\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "# Get list of images\n",
    "files = [f for f in os.listdir(source_dir) if f.lower().endswith(image_extensions)]\n",
    "print(f\"Found {len(files)} images. Processing...\")\n",
    "\n",
    "# 3. Processing Loop\n",
    "count = 0\n",
    "for filename in tqdm(files):\n",
    "    file_path = os.path.join(source_dir, filename)\n",
    "    \n",
    "    # Read Image\n",
    "    img = cv2.imread(file_path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not read {filename}\")\n",
    "        continue\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    # Check if image is large enough\n",
    "    if w < CROP_W or h < CROP_H:\n",
    "        print(f\"Skipping {filename}: Image smaller than crop size ({w}x{h})\")\n",
    "        continue\n",
    "\n",
    "    # 4. Calculate Top-Right Coordinates\n",
    "    # Y: Starts at 0, ends at 640\n",
    "    # X: Starts at (Width - 640), ends at Width\n",
    "    x_start = w - CROP_W\n",
    "    y_start = 0\n",
    "    \n",
    "    # Crop: img[y:y+h, x:x+w]\n",
    "    cropped_img = img[y_start : y_start + CROP_H, x_start : x_start + CROP_W]\n",
    "    \n",
    "    # 5. Save\n",
    "    save_path = os.path.join(output_dir, filename)\n",
    "    cv2.imwrite(save_path, cropped_img)\n",
    "    count += 1\n",
    "\n",
    "print(f\"\\nDone! {count} images saved to:\\n{output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98284c5",
   "metadata": {},
   "source": [
    "## Put cropped images into set1 to set5 folders. (Round Robin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5967aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4945 images. Distributing cyclically into 5 sets...\n",
      "Done! Distribution complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 1. Configuration\n",
    "base_dir = \"/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_sangsun_20221019_f1729_t2029/chungmuro_sangsun_10frames_1920_train_arrival/cropped\"\n",
    "num_sets = 5\n",
    "\n",
    "# 2. Get and Sort Files\n",
    "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "files = [f for f in os.listdir(base_dir) if f.lower().endswith(valid_exts)]\n",
    "files.sort() # Important to keep the sequence (1st, 2nd, 3rd...)\n",
    "\n",
    "print(f\"Found {len(files)} images. Distributing cyclically into {num_sets} sets...\")\n",
    "\n",
    "# Create the set folders first\n",
    "for i in range(1, num_sets + 1):\n",
    "    os.makedirs(os.path.join(base_dir, f\"set{i}\"), exist_ok=True)\n",
    "\n",
    "# 3. Distribute Files Round-Robin\n",
    "for index, filename in enumerate(files):\n",
    "    # Calculate which set (0 to 4) -> (1 to 5)\n",
    "    # 0 % 5 = 0 -> set1\n",
    "    # 1 % 5 = 1 -> set2\n",
    "    # ...\n",
    "    # 5 % 5 = 0 -> set1\n",
    "    set_num = (index % num_sets) + 1\n",
    "    \n",
    "    src_path = os.path.join(base_dir, filename)\n",
    "    dst_path = os.path.join(base_dir, f\"set{set_num}\", filename)\n",
    "    \n",
    "    shutil.move(src_path, dst_path)\n",
    "\n",
    "print(\"Done! Distribution complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa3b26",
   "metadata": {},
   "source": [
    "## Extracting full frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff455ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "VIDEO_PATH    = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/4_2020-11-28_14-21-05.mp4'\n",
    "OUTPUT_FOLDER = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/extracted_frames_10frame'\n",
    "\n",
    "# Video Start Time (Hour, Minute, Second)\n",
    "START_TIME_STR = \"14:21:05\"\n",
    "\n",
    "FRAME_STEP    = 3\n",
    "CROP_SIZE     = 320\n",
    "MARGIN_RIGHT  = 120\n",
    "MARGIN_TOP    = 0\n",
    "# ---------------------\n",
    "\n",
    "def extract_frames_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function to be run by each CPU core.\n",
    "    Now accepts 'fps' and 'start_time_obj' to calculate timestamps.\n",
    "    \"\"\"\n",
    "    video_path, frames_to_process, (dir_crop, dir_orig), (x_start, y_start), fps, start_dt = args\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    \n",
    "    for frame_idx in frames_to_process:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # --- Calculate Timestamp ---\n",
    "            # Seconds elapsed = frame_number / fps\n",
    "            seconds_elapsed = frame_idx / fps\n",
    "            \n",
    "            # Add to start time\n",
    "            current_time = start_dt + timedelta(seconds=seconds_elapsed)\n",
    "            \n",
    "            # Format: HHMMSS (e.g., 070001)\n",
    "            time_str = current_time.strftime(\"%H%M%S\")\n",
    "            \n",
    "            # New Filename: euljiro_070001_frame_000030.jpg\n",
    "            filename = f\"euljiro_{time_str}_frame_{frame_idx:06d}.jpg\"\n",
    "\n",
    "            # 1. Save Original\n",
    "            path_orig = os.path.join(dir_orig, filename)\n",
    "            cv2.imwrite(path_orig, frame)\n",
    "\n",
    "            # 2. Save Cropped\n",
    "            cropped = frame[y_start : y_start + CROP_SIZE, \n",
    "                            x_start : x_start + CROP_SIZE]\n",
    "            \n",
    "            path_crop = os.path.join(dir_crop, filename)\n",
    "            cv2.imwrite(path_crop, cropped)\n",
    "            count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return count\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Folders\n",
    "    dir_crop = os.path.join(OUTPUT_FOLDER, 'cropped')\n",
    "    dir_orig = os.path.join(OUTPUT_FOLDER, 'original')\n",
    "    os.makedirs(dir_crop, exist_ok=True)\n",
    "    os.makedirs(dir_orig, exist_ok=True)\n",
    "\n",
    "    # 2. Parse Start Time\n",
    "    # We use a dummy date (today) because timedelta requires a datetime object\n",
    "    start_dt = datetime.strptime(START_TIME_STR, \"%H:%M:%S\")\n",
    "\n",
    "    # 3. Analyze Video Metadata\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video at {VIDEO_PATH}\")\n",
    "        return\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    cap.release()\n",
    "\n",
    "    # 4. Config\n",
    "    x_start = width - MARGIN_RIGHT - CROP_SIZE\n",
    "    y_start = MARGIN_TOP\n",
    "    \n",
    "    print(f\"Video FPS: {fps}\")\n",
    "    print(f\"Start Time: {START_TIME_STR}\")\n",
    "    print(f\"Total Frames: {total_frames}\")\n",
    "    print(f\"Saving to: {OUTPUT_FOLDER}\")\n",
    "\n",
    "    # 5. Generate Target Indices (Every 10 frames)\n",
    "    target_indices = list(range(0, total_frames, FRAME_STEP))\n",
    "    \n",
    "    print(f\"Extracting {len(target_indices)} frames (Step: {FRAME_STEP}) using {cpu_count()} CPUs...\")\n",
    "\n",
    "    # 6. Distribute work\n",
    "    num_cpus = cpu_count()\n",
    "    chunk_size = math.ceil(len(target_indices) / num_cpus)\n",
    "    \n",
    "    tasks = []\n",
    "    for i in range(0, len(target_indices), chunk_size):\n",
    "        chunk = target_indices[i : i + chunk_size]\n",
    "        # Pass fps and start_dt to worker\n",
    "        tasks.append((VIDEO_PATH, chunk, (dir_crop, dir_orig), (x_start, y_start), fps, start_dt))\n",
    "\n",
    "    # 7. Execute\n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        with tqdm(total=len(target_indices), unit=\"img\") as pbar:\n",
    "            for saved_count in pool.imap_unordered(extract_frames_worker, tasks):\n",
    "                pbar.update(saved_count)\n",
    "\n",
    "    print(\"Done! Files saved with timestamp in name (e.g., euljiro_070001_frame_xxxxxx.jpg)\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc333ca",
   "metadata": {},
   "source": [
    "## Extracting frames and crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# chungmuro hasun config.\n",
    "VIDEO_PATH    = '/media/holidayj/Documents/Videos/videos/platform/euljiro/euljoro_20251111_070000.mp4'\n",
    "OUTPUT_FOLDER = '/media/holidayj/Documents/data/frames/euljiro_rush_20251111'\n",
    "INTERVAL_SEC  = 0.2\n",
    "CROP_SIZE     = 600\n",
    "MARGIN_RIGHT  = 400\n",
    "MARGIN_TOP    = 10\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "VIDEO_PATH    = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20221101_f1700_t2000/euljiro_inner_20221101_f1700_t2000.mp4'\n",
    "# VIDEO_PATH    = '/media/holidayj/Documents/Data/Platform/Chungmuro/chungmuro_hasun_20221019_f1729_t2030/chungmuro_hasun_20221019T172940_20221019T203040.mp4'\n",
    "# VIDEO_PATH    = '/home/holidayj/Videos/videos/platform/chungmuro/chungmuro_sangsun_20221019T172940-20221019T202940/chungmuro_sangsun_20221019T172940-20221019T202940.mp4'\n",
    "\n",
    "OUTPUT_FOLDER = 'frames/euljiro_inner_20221101_f1700_t2000_1sec'\n",
    "INTERVAL_SEC  = 1/3\n",
    "CROP_SIZE     = 700\n",
    "MARGIN_RIGHT  = 400\n",
    "MARGIN_TOP    = 30\n",
    "\n",
    "\n",
    "\n",
    "# OUTPUT_FOLDER = 'frames/chungmuro_hasun_6frames_700'\n",
    "# INTERVAL_SEC  = 0.2\n",
    "# CROP_SIZE     = 700\n",
    "# MARGIN_RIGHT  = 400\n",
    "# MARGIN_TOP    = 30\n",
    "# ---------------------\n",
    "\n",
    "def save_image_worker(args):\n",
    "    \"\"\"\n",
    "    Independent worker function to save the image.\n",
    "    This runs on separate CPUs.\n",
    "    \"\"\"\n",
    "    img_data, save_path = args\n",
    "    cv2.imwrite(save_path, img_data)\n",
    "\n",
    "def main():\n",
    "    # 1. Setup\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video.\")\n",
    "        return\n",
    "\n",
    "    # 2. Metadata\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = np.round(cap.get(cv2.CAP_PROP_FPS))\n",
    "    # print(\"fps =\", np.round(fps))\n",
    "    \n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    \n",
    "    # 3. Crop Config\n",
    "    x_start = width - MARGIN_RIGHT - CROP_SIZE\n",
    "    y_start = MARGIN_TOP\n",
    "    frame_step = int(fps * INTERVAL_SEC)\n",
    "    if frame_step < 1: frame_step = 1\n",
    "\n",
    "    print(f\"FPS: {fps} | Step: {frame_step}\")\n",
    "    print(f\"Using {cpu_count()} CPUs for saving images.\")\n",
    "\n",
    "    # 4. Initialize the Worker Pool (For saving only)\n",
    "    # We use roughly 80% of CPUs to leave room for the main reader process\n",
    "    worker_count = max(1, cpu_count() - 1) \n",
    "    pool = Pool(processes=worker_count)\n",
    "    \n",
    "    current_idx = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    # 5. Fast Reader Loop\n",
    "    # The main loop now NEVER waits for disk I/O. \n",
    "    # It just throws the image to the pool and immediately reads the next one.\n",
    "    with tqdm(total=total_frames, unit=\"frame\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                if current_idx < 100: # Skip initial corruption\n",
    "                    current_idx += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if current_idx % frame_step == 0:\n",
    "                # Crop\n",
    "                cropped = frame[0:1080,\n",
    "                                0:1920]\n",
    "                cropped = frame[y_start : y_start + CROP_SIZE, \n",
    "                                x_start : x_start + CROP_SIZE]\n",
    "                \n",
    "                # Construct path\n",
    "                filename = f\"chungmuro_frame_{current_idx:06d}.jpg\"\n",
    "                save_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "                \n",
    "                # --- ASYNC SAVE ---\n",
    "                # Fire and forget. The main loop continues immediately.\n",
    "                pool.apply_async(save_image_worker, args=((cropped, save_path),))\n",
    "                saved_count += 1\n",
    "\n",
    "            current_idx += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    print(\"\\nReading finished. Waiting for remaining file writes to complete...\")\n",
    "    pool.close()\n",
    "    pool.join() # Wait for the background workers to finish saving\n",
    "    print(f\"Done! Saved {saved_count} images.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8049ed",
   "metadata": {},
   "source": [
    "# This code select frames only those divisible by 30, and crops to get the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f11241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files in: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival\n",
      "Image Size: 1920x1080\n",
      "Crop X: 820 ~ 1520 (Width: 700)\n",
      "Crop Y: 30 ~ 730 (Height: 700)\n",
      "Filtering for every 30th frame...\n",
      "Found 1384 frames to process.\n",
      "Processing with 8 CPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384/1384 [00:15<00:00, 90.24img/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Cropped images saved to: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SOURCE_FOLDER = '/media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival'\n",
    "OUTPUT_FOLDER = os.path.join(SOURCE_FOLDER, '30_frames_crop')\n",
    "\n",
    "# Filter Condition: Every 30 frames (0, 30, 60, 90...)\n",
    "TARGET_FRAME_STEP = 30\n",
    "\n",
    "# Crop Configuration\n",
    "CROP_SIZE     = 700   # 700x700 square\n",
    "MARGIN_RIGHT  = 400\n",
    "MARGIN_TOP    = 30\n",
    "# ---------------------\n",
    "\n",
    "def crop_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function to read an image, crop it, and save it.\n",
    "    args: (file_path, save_path, crop_coords)\n",
    "    crop_coords: (y_start, y_end, x_start, x_end)\n",
    "    \"\"\"\n",
    "    file_path, save_path, (y_s, y_e, x_s, x_e) = args\n",
    "    \n",
    "    img = cv2.imread(file_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    # Crop the image using numpy slicing [y:y+h, x:x+w]\n",
    "    cropped_img = img[y_s:y_e, x_s:x_e]\n",
    "    \n",
    "    cv2.imwrite(save_path, cropped_img)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Folders\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "    # 2. Get list of all images\n",
    "    print(f\"Scanning files in: {SOURCE_FOLDER}\")\n",
    "    all_files = glob.glob(os.path.join(SOURCE_FOLDER, \"*.jpg\"))\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"Error: No images found in source folder.\")\n",
    "        return\n",
    "\n",
    "    # 3. Calculate Crop Coordinates (Based on the first image found)\n",
    "    # We assume all images have the same resolution (likely 1920x1080)\n",
    "    sample_img = cv2.imread(all_files[0])\n",
    "    img_h, img_w = sample_img.shape[:2]\n",
    "    \n",
    "    # Logic: Start X = Width - Margin_Right - Crop_Size\n",
    "    x_start = img_w - MARGIN_RIGHT - CROP_SIZE\n",
    "    x_end   = x_start + CROP_SIZE\n",
    "    y_start = MARGIN_TOP\n",
    "    y_end   = y_start + CROP_SIZE\n",
    "    \n",
    "    crop_coords = (y_start, y_end, x_start, x_end)\n",
    "    \n",
    "    print(f\"Image Size: {img_w}x{img_h}\")\n",
    "    print(f\"Crop X: {x_start} ~ {x_end} (Width: {CROP_SIZE})\")\n",
    "    print(f\"Crop Y: {y_start} ~ {y_end} (Height: {CROP_SIZE})\")\n",
    "\n",
    "    # 4. Filter files: Only keep frames where number % 30 == 0\n",
    "    tasks = []\n",
    "    print(f\"Filtering for every {TARGET_FRAME_STEP}th frame...\")\n",
    "    \n",
    "    for file_path in all_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        # Parse frame number from \"chungmuro_frame_002060.jpg\"\n",
    "        try:\n",
    "            # Split by '_' take last part, remove .jpg extension\n",
    "            frame_part = filename.split('_')[-1] \n",
    "            frame_str = frame_part.split('.')[0]\n",
    "            frame_num = int(frame_str)\n",
    "            \n",
    "            # CHECK CONDITION\n",
    "            if frame_num % TARGET_FRAME_STEP == 0:\n",
    "                save_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "                tasks.append((file_path, save_path, crop_coords))\n",
    "                \n",
    "        except ValueError:\n",
    "            # Skip files that don't match the naming pattern\n",
    "            continue\n",
    "\n",
    "    print(f\"Found {len(tasks)} frames to process.\")\n",
    "    \n",
    "    # 5. Execute Parallel Processing\n",
    "    num_cpus = cpu_count()\n",
    "    print(f\"Processing with {num_cpus} CPUs...\")\n",
    "    \n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        # Use imap to show progress bar\n",
    "        list(tqdm(pool.imap(crop_worker, tasks), total=len(tasks), unit=\"img\"))\n",
    "\n",
    "    print(f\"\\nSuccess! Cropped images saved to: {OUTPUT_FOLDER}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1c2ca",
   "metadata": {},
   "source": [
    "# Applying CLAHE\n",
    "Too much noise? Decrease CLIP_LIMIT from 3.0 to 2.0.\n",
    "\n",
    "Still too dark? Increase CLIP_LIMIT to 4.0 or 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bd16d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning files in: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop\n",
      "Found 1384 images. Applying CLAHE (ClipLimit=5.0)...\n",
      "Processing with 8 CPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384/1384 [00:30<00:00, 45.89img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Enhanced images saved to: /media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop/clahe\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# The folder containing the already cropped images\n",
    "INPUT_FOLDER = '/media/holidayj/Documents/github/ML/Python/annotation/frames/chungmuro_hasun_10frame_1920_train_arrival/30_frames_crop'\n",
    "\n",
    "# The new subfolder for CLAHE images\n",
    "OUTPUT_FOLDER = os.path.join(INPUT_FOLDER, 'clahe')\n",
    "\n",
    "# CLAHE Settings\n",
    "# clipLimit: Higher = more contrast (and more noise). 2.0 to 4.0 is standard.\n",
    "# tileGridSize: Size of the local area to inspect. (8,8) is standard.\n",
    "CLIP_LIMIT = 5.0 \n",
    "GRID_SIZE = (8, 8)\n",
    "# ---------------------\n",
    "\n",
    "def clahe_worker(args):\n",
    "    \"\"\"\n",
    "    Reads an image, applies CLAHE to the Lightness channel, and saves it.\n",
    "    \"\"\"\n",
    "    file_path, save_path = args\n",
    "    \n",
    "    img = cv2.imread(file_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    # 1. Convert BGR to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # 2. Split into L, A, B channels\n",
    "    l_channel, a, b = cv2.split(lab)\n",
    "\n",
    "    # 3. Apply CLAHE to L-channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=CLIP_LIMIT, tileGridSize=GRID_SIZE)\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # 4. Merge the CLAHE enhanced L-channel with the original A and B channels\n",
    "    merged_lab = cv2.merge((cl, a, b))\n",
    "\n",
    "    # 5. Convert back to BGR\n",
    "    final_img = cv2.cvtColor(merged_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    cv2.imwrite(save_path, final_img)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # 1. Setup Folders\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "    # 2. Get list of cropped images\n",
    "    print(f\"Scanning files in: {INPUT_FOLDER}\")\n",
    "    all_files = glob.glob(os.path.join(INPUT_FOLDER, \"*.jpg\"))\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"Error: No images found. Make sure you ran the crop script first.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(all_files)} images. Applying CLAHE (ClipLimit={CLIP_LIMIT})...\")\n",
    "\n",
    "    # 3. Prepare Tasks\n",
    "    tasks = []\n",
    "    for file_path in all_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        save_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "        tasks.append((file_path, save_path))\n",
    "    \n",
    "    # 4. Execute Parallel Processing\n",
    "    num_cpus = cpu_count()\n",
    "    print(f\"Processing with {num_cpus} CPUs...\")\n",
    "    \n",
    "    with Pool(processes=num_cpus) as pool:\n",
    "        list(tqdm(pool.imap(clahe_worker, tasks), total=len(tasks), unit=\"img\"))\n",
    "\n",
    "    print(f\"\\nDone! Enhanced images saved to: {OUTPUT_FOLDER}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17c741",
   "metadata": {},
   "source": [
    "## 폴더안의 프레임수 csv 파일로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf10cec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 5523개의 이미지 파일을 발견했습니다. 처리를 시작합니다...\n",
      "\n",
      "완료! 'frame_intervals_checked.csv' 파일이 생성되었습니다.\n",
      "\n",
      "--- 결과 샘플 (30프레임 구간 확인) ---\n",
      "      video_id  frame  interval  next_interval interval_type\n",
      "774          1   7080         0           30.0         2_sec\n",
      "3923         1   7110        30           30.0          less\n",
      "2974         1   7140        30           30.0         2_sec\n",
      "4731         1   7170        30           30.0          less\n",
      "3641         1   7200        30           30.0         2_sec\n",
      "727          1   7230        30           30.0          less\n",
      "\n",
      "--- Type 분포 ---\n",
      "interval_type\n",
      "2_sec    3801\n",
      "less     1722\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_interval_csv(source_dir, output_csv=\"frame_intervals_checked.csv\"):\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"에러: 경로를 찾을 수 없습니다 -> {source_dir}\")\n",
    "        return\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # 1. 파일 목록 읽기 및 파싱\n",
    "    files = [f for f in os.listdir(source_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    print(f\"총 {len(files)}개의 이미지 파일을 발견했습니다. 처리를 시작합니다...\")\n",
    "\n",
    "    for filename in files:\n",
    "        try:\n",
    "            name_body = os.path.splitext(filename)[0]\n",
    "            parts = name_body.split('_')\n",
    "            \n",
    "            if len(parts) >= 2:\n",
    "                video_id = int(parts[0])\n",
    "                frame_num = int(parts[1])\n",
    "                \n",
    "                data.append({\n",
    "                    'video_id': video_id, \n",
    "                    'frame': frame_num,\n",
    "                    'filename': filename \n",
    "                })\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    if not data:\n",
    "        print(\"처리할 데이터가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # 2. DataFrame 생성 및 정렬\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(by=['video_id', 'frame'])\n",
    "\n",
    "    # 3. Interval 계산 (현재 - 이전)\n",
    "    df['interval'] = df.groupby('video_id')['frame'].diff().fillna(0).astype(int)\n",
    "\n",
    "    # 4. Next Interval 계산 (다음 - 현재)\n",
    "    # 다음 프레임이 얼마나 떨어져 있는지 확인하기 위해 shift(-1) 사용\n",
    "    df['next_interval'] = df.groupby('video_id')['frame'].shift(-1) - df['frame']\n",
    "\n",
    "    # 5. \"2_sec\" vs \"less\" 라벨링 로직 적용\n",
    "    # 상태 의존적(이전 프레임의 결과가 현재에 영향)이므로 순회하며 처리\n",
    "    \n",
    "    labeled_data = []\n",
    "    \n",
    "    # 비디오 ID별로 그룹화하여 처리 (비디오가 바뀌면 상태 리셋)\n",
    "    for vid, group in df.groupby('video_id'):\n",
    "        # 좁은 간격(30프레임 등)이 시작되었는지 추적하는 플래그\n",
    "        # True면 직전 프레임이 \"좁은 간격의 시작(1st)\"이었음을 의미\n",
    "        in_short_gap_sequence = False \n",
    "        \n",
    "        for idx, row in group.iterrows():\n",
    "            next_val = row['next_interval']\n",
    "            \n",
    "            # 마지막 프레임 처리 (next_interval이 NaN)\n",
    "            if pd.isna(next_val):\n",
    "                # 마지막 프레임은 다음 구간이 없으므로, 보통 유지하거나 종료 처리\n",
    "                # 여기서는 'less'로 처리하거나 필요시 '2_sec'으로 변경 가능\n",
    "                row['interval_type'] = '2_sec' \n",
    "            \n",
    "            # Case A: 다음 프레임까지 간격이 충분함 (>35)\n",
    "            elif next_val > 35:\n",
    "                row['interval_type'] = '2_sec'\n",
    "                in_short_gap_sequence = False # 시퀀스 초기화\n",
    "            \n",
    "            # Case B: 다음 프레임까지 간격이 좁음 (<=35, 예: 30)\n",
    "            else:\n",
    "                if in_short_gap_sequence:\n",
    "                    # 이미 좁은 간격이 시작된 상태에서 또 좁은 간격 등장 -> 2번째 프레임 (제거 대상)\n",
    "                    row['interval_type'] = 'less'\n",
    "                    in_short_gap_sequence = False # 하나 건너뛰었으므로 다시 리셋 (다음 30은 다시 2_sec가 됨)\n",
    "                else:\n",
    "                    # 좁은 간격의 첫 번째 프레임 -> 유지\n",
    "                    row['interval_type'] = '2_sec'\n",
    "                    in_short_gap_sequence = True # 플래그 세팅\n",
    "\n",
    "            labeled_data.append(row)\n",
    "\n",
    "    # 결과 데이터프레임 생성\n",
    "    df_final = pd.DataFrame(labeled_data)\n",
    "\n",
    "    # 6. CSV 저장\n",
    "    # 보기 편하게 컬럼 순서 정리\n",
    "    output_cols = ['video_id', 'frame', 'interval', 'next_interval', 'interval_type']\n",
    "    df_final[output_cols].to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"\\n완료! '{output_csv}' 파일이 생성되었습니다.\")\n",
    "    \n",
    "    # 결과 검증 출력\n",
    "    print(\"\\n--- 결과 샘플 (30프레임 구간 확인) ---\")\n",
    "    # next_interval이 35 이하인 구간을 찾아 패턴 확인\n",
    "    sample = df_final[df_final['next_interval'] <= 35].head(6)\n",
    "    if not sample.empty:\n",
    "        print(sample[output_cols])\n",
    "    else:\n",
    "        print(df_final[output_cols].head())\n",
    "\n",
    "    print(\"\\n--- Type 분포 ---\")\n",
    "    print(df_final['interval_type'].value_counts())\n",
    "\n",
    "# 경로 설정\n",
    "target_dir = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/Euljiro_inner_20201128_f1038_t1519/other_tries/new_annotation_skku_30_frames_ing/train_balanced_orig/TrainVal_unbalanced'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_interval_csv(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cc7a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 5523개의 이미지 파일을 분석합니다...\n",
      "\n",
      "이동 시작: 3801개의 '2_sec' 프레임 세트를 'selected_2sec' 폴더로 이동합니다.\n",
      "\n",
      "작업 완료! 총 3801세트의 파일이 이동되었습니다.\n",
      "남은 파일(less)은 원래 폴더에 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def move_2sec_frames(source_dir, subfolder_name=\"selected_2sec\"):\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"에러: 경로를 찾을 수 없습니다 -> {source_dir}\")\n",
    "        return\n",
    "\n",
    "    # 이동할 타겟 폴더 생성\n",
    "    target_dir = os.path.join(source_dir, subfolder_name)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # 1. 파일 리스트업\n",
    "    files = [f for f in os.listdir(source_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"총 {len(files)}개의 이미지 파일을 분석합니다...\")\n",
    "\n",
    "    for filename in files:\n",
    "        try:\n",
    "            name_body = os.path.splitext(filename)[0]\n",
    "            parts = name_body.split('_')\n",
    "            if len(parts) >= 2:\n",
    "                video_id = int(parts[0])\n",
    "                frame_num = int(parts[1])\n",
    "                data.append({'video_id': video_id, 'frame': frame_num, 'filename': filename})\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    if not data:\n",
    "        print(\"데이터가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # 2. 로직 적용 (이전 코드와 동일)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(by=['video_id', 'frame'])\n",
    "\n",
    "    # 다음 프레임과의 간격 계산\n",
    "    df['next_interval'] = df.groupby('video_id')['frame'].shift(-1) - df['frame']\n",
    "\n",
    "    # 2_sec / less 분류\n",
    "    labeled_data = []\n",
    "    for vid, group in df.groupby('video_id'):\n",
    "        in_short_gap_sequence = False \n",
    "        for idx, row in group.iterrows():\n",
    "            next_val = row['next_interval']\n",
    "            \n",
    "            # 마지막 프레임이거나 간격이 충분하면 2_sec (유지)\n",
    "            if pd.isna(next_val) or next_val > 35:\n",
    "                row['interval_type'] = '2_sec'\n",
    "                in_short_gap_sequence = False\n",
    "            else:\n",
    "                # 간격이 좁음 (<=35)\n",
    "                if in_short_gap_sequence:\n",
    "                    row['interval_type'] = 'less' # 이미 좁은 간격 시작됨 -> 제거 대상\n",
    "                    in_short_gap_sequence = False\n",
    "                else:\n",
    "                    row['interval_type'] = '2_sec' # 좁은 간격의 시작 -> 유지\n",
    "                    in_short_gap_sequence = True\n",
    "            \n",
    "            labeled_data.append(row)\n",
    "\n",
    "    df_final = pd.DataFrame(labeled_data)\n",
    "\n",
    "    # 3. 파일 이동 실행\n",
    "    move_count = 0\n",
    "    \n",
    "    # 2_sec로 분류된 파일만 필터링\n",
    "    files_to_move = df_final[df_final['interval_type'] == '2_sec']\n",
    "\n",
    "    print(f\"\\n이동 시작: {len(files_to_move)}개의 '2_sec' 프레임 세트를 '{subfolder_name}' 폴더로 이동합니다.\")\n",
    "\n",
    "    for _, row in files_to_move.iterrows():\n",
    "        img_filename = row['filename']\n",
    "        base_name = os.path.splitext(img_filename)[0]\n",
    "        \n",
    "        src_img_path = os.path.join(source_dir, img_filename)\n",
    "        dst_img_path = os.path.join(target_dir, img_filename)\n",
    "        \n",
    "        # 1) 이미지 이동\n",
    "        if os.path.exists(src_img_path):\n",
    "            shutil.move(src_img_path, dst_img_path)\n",
    "        \n",
    "        # 2) 텍스트 파일(.txt) 이동\n",
    "        txt_filename = base_name + \".txt\"\n",
    "        src_txt_path = os.path.join(source_dir, txt_filename)\n",
    "        dst_txt_path = os.path.join(target_dir, txt_filename)\n",
    "        \n",
    "        if os.path.exists(src_txt_path):\n",
    "            shutil.move(src_txt_path, dst_txt_path)\n",
    "            \n",
    "        move_count += 1\n",
    "\n",
    "    print(f\"\\n작업 완료! 총 {move_count}세트의 파일이 이동되었습니다.\")\n",
    "    print(f\"남은 파일(less)은 원래 폴더에 있습니다.\")\n",
    "\n",
    "# 경로 설정\n",
    "target_dir = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/Euljiro_inner_20201128_f1038_t1519/other_tries/new_annotation_skku_30_frames_ing/train_balanced_orig/TrainVal_unbalanced'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    move_2sec_frames(target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4754836",
   "metadata": {},
   "source": [
    "# Counting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5168e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4882 label files in /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/train\n",
      "\n",
      "Object counts per class:\n",
      "Class 0: 3447\n",
      "Class 1: 3504\n",
      "Class 2: 3537\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the path to your dataset\n",
    "\n",
    "\n",
    "## Euljiro peak and off-peak combined datasets\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_3_Original_dataset_Euljiro_peak_n_offpeak_combined/test/am_peak'\n",
    "\n",
    "# pm peak\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_1_Original_dataset_Eljiro_peak/Euljiro_inner_20221101_f1700_t2000_120_interval_till_1830/val'\n",
    "# AM peak\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_1_Original_dataset_Eljiro_peak/Euljiro_inner_20251111_f0700_t1000_120_frames_interval/val'\n",
    "# off-peak\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_Test'\n",
    "dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/train'\n",
    "\n",
    "\n",
    "# # off-peak test balanced\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_Test'\n",
    "# # off-peak train balanced\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/train'\n",
    "# # off-rush val balanced\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/val'\n",
    "# off-peak TrainVal balanced\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/TrainVal'\n",
    "\n",
    "# # off-peak train  unbalanced\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/Euljiro_off_peak_TrainVal_unbalanced_2sec_FINAL_20260117/train'\n",
    "# # off-rush val unbalanced\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/Euljiro_off_peak_TrainVal_unbalanced_2sec_FINAL_20260117/val'\n",
    "# off-peak TrainVal unbalanced\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/Euljiro_off_peak_TrainVal_unbalanced_2sec_FINAL_20260117/TrainVal'\n",
    "\n",
    "# peak test\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_1_Original_dataset_Eljiro_peak/Euljiro_inner_20221101_f1700_t2000_120_interval_till_1830/test'\n",
    "# peak train\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_1_Original_dataset_Eljiro_peak/Euljiro_inner_20221101_f1700_t2000_120_interval_till_1830/train'\n",
    "# peak val\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_1_Original_dataset_Eljiro_peak/Euljiro_inner_20221101_f1700_t2000_120_interval_till_1830/val' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Chungmuro dataset\n",
    "# sangsun\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/chungmuro/chungmuro_sangsun_20221019_f1729_t2029/train'\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/chungmuro/chungmuro_sangsun_20221019_f1729_t2029/val'\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/chungmuro/chungmuro_sangsun_20221019_f1729_t2029/test'\n",
    "\n",
    "# hasun\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/chungmuro/chungmuro_hasun_20221019_f1729_t2030/train'\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/chungmuro/chungmuro_hasun_20221019_f1729_t2030/val'\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/chungmuro/chungmuro_hasun_20221019_f1729_t2030/test'\n",
    "\n",
    "# 2 class combined off-peak train balanced\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/2_class/Euljiro_off_peak_Test'\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/2_class/Euljiro_off_peak_Test'\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/2_class/Euljiro_off_peak_Test'\n",
    "# dataset_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/2_class/Euljiro_off_peak_Test'\n",
    "\n",
    "\n",
    "# Find all .txt files in the directory\n",
    "label_files = glob.glob(os.path.join(dataset_path, '*.txt'))\n",
    "\n",
    "print(f\"Found {len(label_files)} label files in {dataset_path}\")\n",
    "\n",
    "# Initialize a dictionary to count objects per class\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Iterate through each label file\n",
    "for file_path in label_files:\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                # Ensure the line is not empty\n",
    "                if parts:\n",
    "                    # In YOLO format, the first element is the class ID\n",
    "                    class_id = int(parts[0])\n",
    "                    class_counts[class_id] += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nObject counts per class:\")\n",
    "# Sort by class ID for cleaner output\n",
    "for class_id in sorted(class_counts.keys()):\n",
    "    print(f\"Class {class_id}: {class_counts[class_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb8f9dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/Euljiro_inner_20201128_f1038_t1519/other_tries/new_annotation_skku_30_frames_ing/train_balanced_orig/TrainVal_unbalanced/additional_frames' 폴더에서 1587개의 라벨 파일을 찾았습니다. 분석 중...\n",
      "\n",
      "========================================\n",
      "Class ID   | Existing   | Additional | Total     \n",
      "----------------------------------------------\n",
      "Class 0    | 3470       | 371        | 3841      \n",
      "Class 1    | 2293       | 1529       | 3822      \n",
      "Class 2    | 2975       | 866        | 3841      \n",
      "========================================\n",
      "\n",
      "[Additional Frames Summary]\n",
      " - Class 0: 371 objects\n",
      " - Class 1: 1529 objects\n",
      " - Class 2: 866 objects\n",
      "\n",
      "[Grand Total Summary]\n",
      " - Class 0: 3841 objects\n",
      " - Class 1: 3822 objects\n",
      " - Class 2: 3841 objects\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def count_and_combine_classes(additional_dir, base_counts):\n",
    "    # 1. 추가 프레임 폴더 확인\n",
    "    if not os.path.exists(additional_dir):\n",
    "        print(f\"에러: 경로를 찾을 수 없습니다 -> {additional_dir}\")\n",
    "        return\n",
    "\n",
    "    # 추가된 프레임에서의 카운트를 저장할 변수\n",
    "    additional_counts = Counter()\n",
    "\n",
    "    files = [f for f in os.listdir(additional_dir) if f.endswith('.txt')]\n",
    "    print(f\"'{additional_dir}' 폴더에서 {len(files)}개의 라벨 파일을 찾았습니다. 분석 중...\")\n",
    "\n",
    "    # 2. 텍스트 파일 파싱 및 카운팅\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(additional_dir, filename)\n",
    "        \n",
    "        # 빈 파일 등 에러 처리\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) > 0:\n",
    "                        # YOLO 포맷의 첫 번째 값은 Class ID\n",
    "                        class_id = int(parts[0])\n",
    "                        additional_counts[class_id] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"파일 읽기 오류 ({filename}): {e}\")\n",
    "\n",
    "    # 3. 결과 합산 및 출력\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"{'Class ID':<10} | {'Existing':<10} | {'Additional':<10} | {'Total':<10}\")\n",
    "    print(\"-\" * 46)\n",
    "\n",
    "    # 0, 1, 2 클래스에 대해 순서대로 출력 (데이터에 없는 클래스가 있을 수도 있으므로 union 사용)\n",
    "    all_classes = sorted(set(base_counts.keys()) | set(additional_counts.keys()))\n",
    "\n",
    "    total_counts = {}\n",
    "\n",
    "    for cls in all_classes:\n",
    "        existing = base_counts.get(cls, 0)\n",
    "        added = additional_counts[cls]\n",
    "        total = existing + added\n",
    "        total_counts[cls] = total\n",
    "        \n",
    "        print(f\"Class {cls:<4} | {existing:<10} | {added:<10} | {total:<10}\")\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # 요약 정보\n",
    "    print(f\"\\n[Additional Frames Summary]\")\n",
    "    for cls, count in sorted(additional_counts.items()):\n",
    "        print(f\" - Class {cls}: {count} objects\")\n",
    "        \n",
    "    print(f\"\\n[Grand Total Summary]\")\n",
    "    for cls, count in sorted(total_counts.items()):\n",
    "        print(f\" - Class {cls}: {count} objects\")\n",
    "\n",
    "# --- 설정 ---\n",
    "\n",
    "# 1. 추가할 프레임들이 있는 경로\n",
    "target_dir = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/Euljiro_inner_20201128_f1038_t1519/other_tries/new_annotation_skku_30_frames_ing/train_balanced_orig/TrainVal_unbalanced/additional_frames'\n",
    "\n",
    "# 2. 기존 2초 간격 프레임의 객체 수 (User가 제공한 값)\n",
    "current_base_counts = {\n",
    "    0: 3470,\n",
    "    1: 2293,\n",
    "    2: 2975\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count_and_combine_classes(target_dir, current_base_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd4329e",
   "metadata": {},
   "source": [
    "## extracting new frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1cf670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 생성됨: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/extracted_new_frames\n",
      "총 6452개의 새로운 프레임을 추출합니다...\n",
      "--- 처리 중: 1_2020-11-28_10-41-45.mp4 (ID: 1) ---\n",
      "  -> 1121장 추출 완료\n",
      "--- 처리 중: 2_2020-11-28_11-33-40.mp4 (ID: 2) ---\n",
      "  -> 1649장 추출 완료\n",
      "--- 처리 중: 3_2020-11-28_13-01-02.mp4 (ID: 3) ---\n",
      "  -> 1423장 추출 완료\n",
      "--- 처리 중: 5_2020-11-28_15-19-51.mp4 (ID: 5) ---\n",
      "  -> 2259장 추출 완료\n",
      "\n",
      "모든 작업이 완료되었습니다. 결과물은 '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/extracted_new_frames' 폴더를 확인하세요.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_frames_from_video():\n",
    "    # --- 설정 영역 ---\n",
    "    # 기본 경로 (비디오 파일과 CSV가 있는 루트 폴더)\n",
    "    base_dir = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519'\n",
    "    \n",
    "    # CSV 파일 경로\n",
    "    csv_path = os.path.join(base_dir, 'frame_intervals_filled.csv')\n",
    "    \n",
    "    # 추출된 이미지를 저장할 폴더 (새로 생성됨)\n",
    "    output_dir = os.path.join(base_dir, 'extracted_new_frames')\n",
    "\n",
    "    # 비디오 ID와 파일명 매핑\n",
    "    video_map = {\n",
    "        1: \"1_2020-11-28_10-41-45.mp4\",\n",
    "        2: \"2_2020-11-28_11-33-40.mp4\",\n",
    "        3: \"3_2020-11-28_13-01-02.mp4\",\n",
    "        4: \"4_2020-11-28_14-21-05.mp4\",\n",
    "        5: \"5_2020-11-28_15-19-51.mp4\"\n",
    "    }\n",
    "    # ----------------\n",
    "\n",
    "    # 1. 출력 폴더 생성\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"폴더 생성됨: {output_dir}\")\n",
    "\n",
    "    # 2. CSV 파일 읽기\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"에러: CSV 파일을 찾을 수 없습니다 -> {csv_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 'new' 상태인 프레임만 필터링\n",
    "    new_frames_df = df[df['status'] == 'new']\n",
    "    \n",
    "    if new_frames_df.empty:\n",
    "        print(\"추출할 'new' 프레임이 없습니다.\")\n",
    "        return\n",
    "\n",
    "    print(f\"총 {len(new_frames_df)}개의 새로운 프레임을 추출합니다...\")\n",
    "\n",
    "    # 3. 비디오별로 그룹화하여 처리 (비디오 로딩 횟수 최소화)\n",
    "    for video_id, group in new_frames_df.groupby('video_id'):\n",
    "        if video_id not in video_map:\n",
    "            print(f\"경고: video_id {video_id}에 해당하는 파일명이 매핑되지 않았습니다. 건너뜁니다.\")\n",
    "            continue\n",
    "\n",
    "        video_filename = video_map[video_id]\n",
    "        video_path = os.path.join(base_dir, video_filename)\n",
    "\n",
    "        print(f\"--- 처리 중: {video_filename} (ID: {video_id}) ---\")\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"에러: 비디오를 열 수 없습니다 -> {video_path}\")\n",
    "            continue\n",
    "\n",
    "        count = 0\n",
    "        for _, row in group.iterrows():\n",
    "            frame_num = int(row['frame'])\n",
    "            \n",
    "            # 해당 프레임으로 이동\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame_img = cap.read()\n",
    "\n",
    "            if ret:\n",
    "                # 파일명 생성 (예: 1_007080.jpg) -> 6자리 숫자로 패딩\n",
    "                output_filename = f\"{video_id}_{frame_num:06d}.jpg\"\n",
    "                save_path = os.path.join(output_dir, output_filename)\n",
    "                \n",
    "                cv2.imwrite(save_path, frame_img)\n",
    "                count += 1\n",
    "            else:\n",
    "                print(f\"실패: 프레임 {frame_num}을 읽을 수 없습니다.\")\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"  -> {count}장 추출 완료\")\n",
    "\n",
    "    print(f\"\\n모든 작업이 완료되었습니다. 결과물은 '{output_dir}' 폴더를 확인하세요.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_frames_from_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c5e1e",
   "metadata": {},
   "source": [
    "## Extracting missing video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a85eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotation file: /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519/new_annotation_skku_30_frames/temp.xlsx\n",
      "Found 2 frames to extract.\n",
      "Processing Video 1: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/1_2020-11-28_10-41-45.mp4 ...\n",
      "Processing Video 2: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/2_2020-11-28_11-33-40.mp4 ...\n",
      "------------------------------\n",
      "Extraction Complete.\n",
      "Frames extracted: 2\n",
      "Errors: 0\n",
      "Saved to: /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519/new_annotation_skku_30_frames/extracted_frame\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. Configuration\n",
    "# ==========================================\n",
    "\n",
    "# Path to your Excel/CSV file\n",
    "excel_file_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519/new_annotation_skku_30_frames/temp.xlsx'\n",
    "\n",
    "# Path to the folder containing the MP4 video files\n",
    "# (Based on your paths, I assume they are in the parent folder. Update this if they are elsewhere)\n",
    "video_source_dir = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519'\n",
    "\n",
    "# Output directory for extracted frames\n",
    "output_dir = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519/new_annotation_skku_30_frames/extracted_frame'\n",
    "\n",
    "# Map Video ID to Filenames\n",
    "video_map = {\n",
    "    1: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/1_2020-11-28_10-41-45.mp4\",\n",
    "    2: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/2_2020-11-28_11-33-40.mp4\",\n",
    "    3: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/3_2020-11-28_13-01-02.mp4\",\n",
    "    4: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/4_2020-11-28_14-21-05.mp4\",\n",
    "    5: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/5_2020-11-28_15-19-51.mp4\"\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. Setup\n",
    "# ==========================================\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "print(f\"Loading annotation file: {excel_file_path}\")\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    if excel_file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(excel_file_path)\n",
    "    else:\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df['status'] = df['status'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Filter for \"new extraction\"\n",
    "# (Checking for both \"new extraction\" and \"new_extraction\" just in case)\n",
    "extract_df = df[df['status'].isin(['new extraction', 'new_extraction'])]\n",
    "\n",
    "print(f\"Found {len(extract_df)} frames to extract.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. Extraction Loop\n",
    "# ==========================================\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "# We'll open video captures as needed to be efficient, or open/close per file.\n",
    "# Since frames might be scattered, opening/closing per frame is slow. \n",
    "# Better: Group by video_id.\n",
    "\n",
    "for vid_id, group in extract_df.groupby('video_id'):\n",
    "    vid_id = int(vid_id)\n",
    "    \n",
    "    if vid_id not in video_map:\n",
    "        print(f\"Warning: Video ID {vid_id} not defined in video_map. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    video_filename = video_map[vid_id]\n",
    "    video_path = os.path.join(video_source_dir, video_filename)\n",
    "    \n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file not found: {video_path}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing Video {vid_id}: {video_filename} ...\")\n",
    "    \n",
    "    # Open Video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_filename}\")\n",
    "        continue\n",
    "        \n",
    "    # Iterate through frames for this video\n",
    "    for _, row in group.iterrows():\n",
    "        frame_num = int(row['frame_num'])\n",
    "        \n",
    "        # Construct output filename: e.g., 1_000060.jpg\n",
    "        output_filename = f\"{vid_id}_{frame_num:06d}.jpg\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        try:\n",
    "            # Set frame position (0-based index)\n",
    "            # If your frame numbers are 1-based, use (frame_num - 1)\n",
    "            # Assuming 0-based based on standard CV practices.\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                cv2.imwrite(output_path, frame)\n",
    "                # print(f\"Saved: {output_filename}\") # Uncomment for verbose output\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"Error: Could not read frame {frame_num} from {video_filename}\")\n",
    "                error_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Exception extracting {output_filename}: {e}\")\n",
    "            error_count += 1\n",
    "            \n",
    "    cap.release()\n",
    "\n",
    "# ==========================================\n",
    "# 4. Summary\n",
    "# ==========================================\n",
    "print(\"-\" * 30)\n",
    "print(f\"Extraction Complete.\")\n",
    "print(f\"Frames extracted: {success_count}\")\n",
    "print(f\"Errors: {error_count}\")\n",
    "print(f\"Saved to: {output_dir}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe6b14",
   "metadata": {},
   "source": [
    "## Template matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9129848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HD Image: /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519/new_annotation_skku_30_frames/extracted_frame/2_116880_hd.jpg\n",
      "Loading Crop Image: /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519/new_annotation_skku_30_frames/extracted_frame/2_116880.jpg\n",
      "------------------------------\n",
      "Match Confidence: 0.99912 (1.0 is a perfect match)\n",
      "FOUND EXACT LOCATION!\n",
      "Top-Left (x, y)     : (1327, 120)\n",
      "Bottom-Right (x, y) : (1647, 440)\n",
      "Crop Width/Height   : 320 x 320\n",
      "\n",
      "Python Crop Code Hint:\n",
      "cropped = original[120:440, 1327:1647]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# Configuration\n",
    "# ==========================================\n",
    "# Path to the HD (Original) Image\n",
    "hd_image_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519/new_annotation_skku_30_frames/extracted_frame/2_116880_hd.jpg'\n",
    "\n",
    "# Path to the Cropped Image\n",
    "# (I adjusted the path slightly based on your likely folder structure, please verify)\n",
    "crop_image_path = '/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro_inner_20201128_f1038_t1519/new_annotation_skku_30_frames/extracted_frame/2_116880.jpg'\n",
    "\n",
    "# ==========================================\n",
    "# Processing\n",
    "# ==========================================\n",
    "print(f\"Loading HD Image: {hd_image_path}\")\n",
    "print(f\"Loading Crop Image: {crop_image_path}\")\n",
    "\n",
    "# 1. Load images\n",
    "img_hd = cv2.imread(hd_image_path)\n",
    "img_crop = cv2.imread(crop_image_path)\n",
    "\n",
    "if img_hd is None or img_crop is None:\n",
    "    print(\"Error: Could not load one or both images. Check file paths.\")\n",
    "else:\n",
    "    # 2. Perform Template Matching\n",
    "    # TM_CCOEFF_NORMED is robust for finding exact matches\n",
    "    result = cv2.matchTemplate(img_hd, img_crop, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    # 3. Find the location of the best match\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    \n",
    "    # max_loc gives the top-left (x, y) of the best match\n",
    "    top_left = max_loc\n",
    "    confidence = max_val\n",
    "    \n",
    "    # 4. Calculate Bottom-Right\n",
    "    h, w = img_crop.shape[:2]\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Match Confidence: {confidence:.5f} (1.0 is a perfect match)\")\n",
    "    \n",
    "    if confidence > 0.99:\n",
    "        print(f\"FOUND EXACT LOCATION!\")\n",
    "        print(f\"Top-Left (x, y)     : {top_left}\")\n",
    "        print(f\"Bottom-Right (x, y) : {bottom_right}\")\n",
    "        print(f\"Crop Width/Height   : {w} x {h}\")\n",
    "        \n",
    "        # Python Slicing Format: [y1:y2, x1:x2]\n",
    "        print(f\"\\nPython Crop Code Hint:\")\n",
    "        print(f\"cropped = original[{top_left[1]}:{bottom_right[1]}, {top_left[0]}:{bottom_right[0]}]\")\n",
    "    else:\n",
    "        print(\"Warning: Match confidence is low. The crop might be resized or modified.\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d588e",
   "metadata": {},
   "source": [
    "## Crop hd frame to 320*320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96af05af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/extracted_new_frames/cropped\n",
      "Source Directory: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/extracted_new_frames\n",
      "Crop Target: y[120:440], x[1327:1647]\n",
      "------------------------------\n",
      "Processing Complete.\n",
      "Images Cropped: 6452\n",
      "Errors/Skipped: 0\n",
      "Saved to: /media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/extracted_new_frames/cropped\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. Configuration\n",
    "# ==========================================\n",
    "# Input folder containing the full HD frames\n",
    "source_dir = '/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/extracted_new_frames'\n",
    "\n",
    "# Output folder for the cropped images\n",
    "output_dir = os.path.join(source_dir, 'cropped')\n",
    "\n",
    "# Crop Coordinates (Found from previous step)\n",
    "# Slice format: [y_start : y_end, x_start : x_end]\n",
    "# Top-Left (x, y): (1327, 120)\n",
    "# Bottom-Right (x, y): (1647, 440)\n",
    "y_start, y_end = 120, 440\n",
    "x_start, x_end = 1327, 1647\n",
    "\n",
    "# ==========================================\n",
    "# 2. Processing\n",
    "# ==========================================\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "print(f\"Source Directory: {source_dir}\")\n",
    "print(f\"Crop Target: y[{y_start}:{y_end}], x[{x_start}:{x_end}]\")\n",
    "\n",
    "processed_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        \n",
    "        file_path = os.path.join(source_dir, filename)\n",
    "        \n",
    "        # Read the image\n",
    "        img = cv2.imread(file_path)\n",
    "        \n",
    "        if img is None:\n",
    "            print(f\"Error: Could not read {filename}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Check if image is large enough to crop\n",
    "        h, w = img.shape[:2]\n",
    "        if h < y_end or w < x_end:\n",
    "            print(f\"Skipping {filename}: Image too small ({w}x{h}) for crop coordinates.\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "            \n",
    "        # Perform Crop\n",
    "        cropped_img = img[y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        # Save\n",
    "        save_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(save_path, cropped_img)\n",
    "        \n",
    "        processed_count += 1\n",
    "\n",
    "# ==========================================\n",
    "# 3. Summary\n",
    "# ==========================================\n",
    "print(\"-\" * 30)\n",
    "print(f\"Processing Complete.\")\n",
    "print(f\"Images Cropped: {processed_count}\")\n",
    "print(f\"Errors/Skipped: {error_count}\")\n",
    "print(f\"Saved to: {output_dir}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2ebb5",
   "metadata": {},
   "source": [
    "## Crop and save passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9093d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3447 label files. Starting processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3447/3447 [00:14<00:00, 239.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SOURCE_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/Euljiro_off_peak_TrainVal_unbalanced_2sec_FINAL_20260117/TrainVal_combined\"\n",
    "OUTPUT_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/cropped_passengers\"\n",
    "\n",
    "# Margin Ratio (0.2 = 20% padding on each side)\n",
    "MARGIN_RATIO = 0.1\n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "# --- CORRECTED CLASS MAPPING ---\n",
    "# You must check your 'classes.txt' file to see which ID belongs to which name.\n",
    "# I am assuming 0=Up, 1=Down, 2=Pass based on your description.\n",
    "# If your order is different, swap the numbers here!\n",
    "CLASS_MAP = {\n",
    "    0: 'U',  # Up\n",
    "    1: 'D',  # Down\n",
    "    2: 'P',  # Pass\n",
    "}\n",
    "\n",
    "def safe_crop_with_padding(image, box_coords, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Crops the image with zero-padding (black borders) for out-of-bound areas.\n",
    "    box_coords: [x1, y1, x2, y2] (Absolute pixel values, can be outside image)\n",
    "    \"\"\"\n",
    "    h_img, w_img, _ = image.shape\n",
    "    x1, y1, x2, y2 = box_coords\n",
    "    \n",
    "    # 1. Calculate desired width/height\n",
    "    cw, ch = x2 - x1, y2 - y1\n",
    "    \n",
    "    # 2. Create black canvas\n",
    "    canvas = np.zeros((ch, cw, 3), dtype=image.dtype)\n",
    "    \n",
    "    # 3. Calculate intersection with actual image\n",
    "    x1_valid = max(0, x1)\n",
    "    y1_valid = max(0, y1)\n",
    "    x2_valid = min(w_img, x2)\n",
    "    y2_valid = min(h_img, y2)\n",
    "    \n",
    "    # 4. Paste valid intersection onto canvas\n",
    "    if x1_valid < x2_valid and y1_valid < y2_valid:\n",
    "        crop_valid = image[y1_valid:y2_valid, x1_valid:x2_valid]\n",
    "        \n",
    "        # Calculate offsets on canvas\n",
    "        off_x = x1_valid - x1\n",
    "        off_y = y1_valid - y1\n",
    "        \n",
    "        canvas[off_y : off_y + crop_valid.shape[0], \n",
    "               off_x : off_x + crop_valid.shape[1]] = crop_valid\n",
    "               \n",
    "    # 5. Resize to standard CNN input size\n",
    "    return cv2.resize(canvas, target_size)\n",
    "\n",
    "def process_dataset():\n",
    "    # Create output subfolders\n",
    "    for class_name in set(CLASS_MAP.values()):\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"U\"), exist_ok=True) # Fallback folder\n",
    "\n",
    "    # Get list of text files\n",
    "    txt_files = glob.glob(os.path.join(SOURCE_DIR, \"*.txt\"))\n",
    "    \n",
    "    print(f\"Found {len(txt_files)} label files. Starting processing...\")\n",
    "\n",
    "    for txt_path in tqdm(txt_files):\n",
    "        # 1. Parse filename to get ID and Frame\n",
    "        base_name = os.path.basename(txt_path)\n",
    "        file_root = os.path.splitext(base_name)[0] # e.g., \"5_179640\"\n",
    "        \n",
    "        # Find matching image (try jpg, then png)\n",
    "        img_path = os.path.join(SOURCE_DIR, file_root + \".jpg\")\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(SOURCE_DIR, file_root + \".png\")\n",
    "            if not os.path.exists(img_path):\n",
    "                continue # Skip if no image found\n",
    "\n",
    "        # 2. Load Image\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        h_img, w_img, _ = img.shape\n",
    "\n",
    "        # 3. Read Labels\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # 4. Process each object\n",
    "        for idx, line in enumerate(lines):\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5: continue\n",
    "            \n",
    "            cls_id = int(parts[0])\n",
    "            # YOLO format: x_center, y_center, width, height (Normalized 0-1)\n",
    "            n_xc, n_yc, n_w, n_h = map(float, parts[1:5])\n",
    "            \n",
    "            # Convert to Pixel Coordinates (x1, y1, x2, y2)\n",
    "            w_box = int(n_w * w_img)\n",
    "            h_box = int(n_h * h_img)\n",
    "            x_center = int(n_xc * w_img)\n",
    "            y_center = int(n_yc * h_img)\n",
    "            \n",
    "            x1 = x_center - w_box // 2\n",
    "            y1 = y_center - h_box // 2\n",
    "            x2 = x1 + w_box\n",
    "            y2 = y1 + h_box\n",
    "            \n",
    "            # 5. Apply Safe Margin (Padding)\n",
    "            pad_w = int(w_box * MARGIN_RATIO)\n",
    "            pad_h = int(h_box * MARGIN_RATIO)\n",
    "            \n",
    "            # Coordinates can go negative or exceed image size (Safe Crop handles this)\n",
    "            crop_coords = [x1 - pad_w, y1 - pad_h, x2 + pad_w, y2 + pad_h]\n",
    "            \n",
    "            # 6. Crop\n",
    "            cropped_img = safe_crop_with_padding(img, crop_coords, TARGET_SIZE)\n",
    "            \n",
    "            # 7. Generate Filename\n",
    "            # Format: {video_id}_{frame}_{Class}_{Index}.jpg\n",
    "            # Index is 0-padded (e.g., 00, 01, 02)\n",
    "            cls_name = CLASS_MAP.get(cls_id, 'U')\n",
    "            obj_index = f\"{idx:02d}\" \n",
    "            \n",
    "            save_name = f\"{file_root}_{cls_name}_{obj_index}.jpg\"\n",
    "            save_path = os.path.join(OUTPUT_DIR, cls_name, save_name)\n",
    "            \n",
    "            # 8. Save\n",
    "            cv2.imwrite(save_path, cropped_img)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c7e1b",
   "metadata": {},
   "source": [
    "## Extracting frames t-1 and t-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0739de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3447 source images. Building task list...\n",
      "Processing 3447 sequences (3 frames each)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3447 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3447/3447 [13:54<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Complete: All 3 frames (t, t-1, t-2) saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SOURCE_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/Euljiro_off_peak_TrainVal_unbalanced_2sec_FINAL_20260117/TrainVal_combined\"\n",
    "OUTPUT_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/extracted_frames_t_t1_t2\"\n",
    "\n",
    "VIDEO_PATHS = {\n",
    "    1: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/1_2020-11-28_10-41-45.mp4\",\n",
    "    2: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/2_2020-11-28_11-33-40.mp4\",\n",
    "    3: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/3_2020-11-28_13-01-02.mp4\",\n",
    "    4: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/4_2020-11-28_14-21-05.mp4\",\n",
    "    5: \"/media/holidayj/Documents/Data/Platform/Euljiro/Euljiro_inner_20201128_f1038_t1519/5_2020-11-28_15-19-51.mp4\"\n",
    "}\n",
    "\n",
    "def extract_all_three_frames():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # 1. Parse all filenames from SOURCE_DIR to find targets\n",
    "    jpg_files = glob.glob(os.path.join(SOURCE_DIR, \"*.jpg\"))\n",
    "    print(f\"Found {len(jpg_files)} source images. Building task list...\")\n",
    "\n",
    "    tasks = []\n",
    "    for jpg_path in jpg_files:\n",
    "        base_name = os.path.basename(jpg_path)\n",
    "        file_root = os.path.splitext(base_name)[0]\n",
    "        try:\n",
    "            parts = file_root.split('_')\n",
    "            vid_id = int(parts[0])\n",
    "            frame_num = int(parts[1])\n",
    "            tasks.append({'vid_id': vid_id, 'frame_num': frame_num})\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "\n",
    "    # 2. Sort by Video -> Frame (Optimization)\n",
    "    tasks.sort(key=lambda x: (x['vid_id'], x['frame_num']))\n",
    "\n",
    "    current_vid_id = None\n",
    "    cap = None\n",
    "    \n",
    "    print(f\"Processing {len(tasks)} sequences (3 frames each)...\")\n",
    "    \n",
    "    for i in tqdm(range(len(tasks))):\n",
    "        t = tasks[i]\n",
    "        vid_id = t['vid_id']\n",
    "        target_frame = t['frame_num']\n",
    "        \n",
    "        # Calculate Frame Numbers\n",
    "        f_t2 = max(0, target_frame - 2)\n",
    "        f_t1 = max(0, target_frame - 1)\n",
    "        f_t0 = target_frame \n",
    "        \n",
    "        frames_to_extract = [f_t2, f_t1, f_t0]\n",
    "        \n",
    "        # Check if they already exist\n",
    "        all_exist = True\n",
    "        for f_num in frames_to_extract:\n",
    "            path = os.path.join(OUTPUT_DIR, f\"{vid_id}_{f_num:06d}.jpg\")\n",
    "            if not os.path.exists(path):\n",
    "                all_exist = False\n",
    "                break\n",
    "        \n",
    "        if all_exist:\n",
    "            continue\n",
    "\n",
    "        # Open Video if changed\n",
    "        if vid_id != current_vid_id:\n",
    "            if cap is not None: cap.release()\n",
    "            video_path = VIDEO_PATHS.get(vid_id)\n",
    "            if video_path is None: continue\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            current_vid_id = vid_id\n",
    "        \n",
    "        if cap is None or not cap.isOpened(): continue\n",
    "\n",
    "        # --- SMART SEEK ---\n",
    "        # We start reading at T-2\n",
    "        start_frame = frames_to_extract[0]\n",
    "        current_pos = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        \n",
    "        dist = start_frame - current_pos\n",
    "        \n",
    "        # If we are close (0 to 20 frames), read forward. Otherwise seek.\n",
    "        if 0 <= dist < 20:\n",
    "            for _ in range(dist):\n",
    "                cap.read()\n",
    "        else:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "        # --- EXTRACT 3 CONSECUTIVE FRAMES ---\n",
    "        # Read T-2, T-1, T0 sequentially\n",
    "        for f_num in frames_to_extract:\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                save_path = os.path.join(OUTPUT_DIR, f\"{vid_id}_{f_num:06d}.jpg\")\n",
    "                # Only save if we strictly need it (skip existing to save IO)\n",
    "                if not os.path.exists(save_path):\n",
    "                    cv2.imwrite(save_path, frame)\n",
    "            else:\n",
    "                break # Stop if video ends\n",
    "\n",
    "    if cap is not None: cap.release()\n",
    "    print(\"Extraction Complete: All 3 frames (t, t-1, t-2) saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_all_three_frames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118f696",
   "metadata": {},
   "source": [
    "## Crop the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15357e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10339 frames to crop. Starting ROI processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10339 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10339/10339 [04:45<00:00, 36.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 Complete. All frames cropped to ROI (320x320).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Source: The folder where we saved the Full HD t-1 and t-2 frames in Step 1\n",
    "SOURCE_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/extracted_frames_t_t1_t2\"\n",
    "\n",
    "# Output: Where to save the 320x320 ROI cropped frames\n",
    "OUTPUT_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/roi_frames_320x320\"\n",
    "\n",
    "# ROI Coordinates\n",
    "Y_START, Y_END = 120, 440\n",
    "X_START, X_END = 1327, 1647\n",
    "\n",
    "def crop_roi_frames():\n",
    "    # Create output directory\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Get all jpg files from the source directory\n",
    "    # This includes both _t1.jpg and _t2.jpg files\n",
    "    img_files = glob.glob(os.path.join(SOURCE_DIR, \"*.jpg\"))\n",
    "    \n",
    "    print(f\"Found {len(img_files)} frames to crop. Starting ROI processing...\")\n",
    "    \n",
    "    for img_path in tqdm(img_files):\n",
    "        # 1. Read the Full HD Image\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read {img_path}\")\n",
    "            continue\n",
    "\n",
    "        # 2. Apply Fixed ROI Crop\n",
    "        # Note: numpy slicing is [y:y_end, x:x_end]\n",
    "        roi_crop = img[Y_START:Y_END, X_START:X_END]\n",
    "        \n",
    "        # Optional validation: Check if size is correct (320x320)\n",
    "        if roi_crop.shape[0] != (Y_END - Y_START) or roi_crop.shape[1] != (X_END - X_START):\n",
    "            print(f\"Warning: Crop size mismatch for {img_path}. Check coordinates.\")\n",
    "        \n",
    "        # 3. Save to Output Directory\n",
    "        # We keep the same filename (e.g., 5_179640_t1.jpg)\n",
    "        filename = os.path.basename(img_path)\n",
    "        save_path = os.path.join(OUTPUT_DIR, filename)\n",
    "        \n",
    "        cv2.imwrite(save_path, roi_crop)\n",
    "\n",
    "    print(\"Step 2 Complete. All frames cropped to ROI (320x320).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crop_roi_frames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcb13f",
   "metadata": {},
   "source": [
    "## Crop passenger object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b290897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3447 labels. Generating temporal crops...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3447/3447 [00:24<00:00, 138.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# 1. Where your labeled text files and images are located\n",
    "SOURCE_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/roi_frames_320x320\"\n",
    "\n",
    "# 2. Where the extracted full frames (from the previous step) are located\n",
    "# We need to look here to find the t-1 and t-2 images.\n",
    "EXTRACTED_FRAMES_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/roi_frames_320x320\"\n",
    "\n",
    "# 3. Where to save the final cropped passenger triplets\n",
    "OUTPUT_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/cropped_passengers_temporal\"\n",
    "\n",
    "MARGIN_RATIO = 0.1\n",
    "CLASS_MAP = {0: 'U', 1: 'D', 2: 'P'}\n",
    "\n",
    "def safe_crop_with_padding(image, box_coords):\n",
    "    h_img, w_img, _ = image.shape\n",
    "    x1, y1, x2, y2 = box_coords\n",
    "    cw, ch = x2 - x1, y2 - y1\n",
    "    canvas = np.zeros((ch, cw, 3), dtype=image.dtype)\n",
    "    \n",
    "    x1_valid = max(0, x1)\n",
    "    y1_valid = max(0, y1)\n",
    "    x2_valid = min(w_img, x2)\n",
    "    y2_valid = min(h_img, y2)\n",
    "    \n",
    "    if x1_valid < x2_valid and y1_valid < y2_valid:\n",
    "        crop_valid = image[y1_valid:y2_valid, x1_valid:x2_valid]\n",
    "        off_x = x1_valid - x1\n",
    "        off_y = y1_valid - y1\n",
    "        canvas[off_y : off_y + crop_valid.shape[0], off_x : off_x + crop_valid.shape[1]] = crop_valid\n",
    "               \n",
    "    return canvas\n",
    "\n",
    "def process_temporal_crops():\n",
    "    # Create output subfolders\n",
    "    for class_name in set(CLASS_MAP.values()):\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, \"U\"), exist_ok=True)\n",
    "\n",
    "    # We iterate based on the LABEL files (Frame t)\n",
    "    txt_files = glob.glob(os.path.join(SOURCE_DIR, \"*.txt\"))\n",
    "    \n",
    "    print(f\"Found {len(txt_files)} labels. Generating temporal crops...\")\n",
    "\n",
    "    for txt_path in tqdm(txt_files):\n",
    "        # 1. Identify Frame t info\n",
    "        base_name = os.path.basename(txt_path)\n",
    "        file_root = os.path.splitext(base_name)[0]\n",
    "        \n",
    "        try:\n",
    "            parts = file_root.split('_')\n",
    "            vid_id = int(parts[0])\n",
    "            frame_t = int(parts[1])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # 2. Determine filenames for t, t-1, t-2\n",
    "        # We look for these in the EXTRACTED_FRAMES_DIR we created earlier\n",
    "        # Format: {vid_id}_{frame:06d}.jpg\n",
    "        fname_t0 = f\"{vid_id}_{frame_t:06d}.jpg\"\n",
    "        fname_t1 = f\"{vid_id}_{frame_t-1:06d}.jpg\"\n",
    "        fname_t2 = f\"{vid_id}_{frame_t-2:06d}.jpg\"\n",
    "        \n",
    "        path_t0 = os.path.join(EXTRACTED_FRAMES_DIR, fname_t0)\n",
    "        path_t1 = os.path.join(EXTRACTED_FRAMES_DIR, fname_t1)\n",
    "        path_t2 = os.path.join(EXTRACTED_FRAMES_DIR, fname_t2)\n",
    "\n",
    "        # Skip if any frame is missing (e.g. at the very start of a video)\n",
    "        if not (os.path.exists(path_t0) and os.path.exists(path_t1) and os.path.exists(path_t2)):\n",
    "            continue\n",
    "\n",
    "        # 3. Load Images\n",
    "        img_t0 = cv2.imread(path_t0)\n",
    "        img_t1 = cv2.imread(path_t1)\n",
    "        img_t2 = cv2.imread(path_t2)\n",
    "        \n",
    "        if img_t0 is None: continue\n",
    "        h_img, w_img, _ = img_t0.shape\n",
    "\n",
    "        # 4. Read Labels (from Frame t)\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # 5. Process each passenger\n",
    "        for idx, line in enumerate(lines):\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5: continue\n",
    "            \n",
    "            cls_id = int(parts[0])\n",
    "            n_xc, n_yc, n_w, n_h = map(float, parts[1:5])\n",
    "            \n",
    "            # --- CALCULATE BOX (Based on Frame t) ---\n",
    "            w_box = int(n_w * w_img)\n",
    "            h_box = int(n_h * h_img)\n",
    "            x_center = int(n_xc * w_img)\n",
    "            y_center = int(n_yc * h_img)\n",
    "            \n",
    "            x1 = x_center - w_box // 2\n",
    "            y1 = y_center - h_box // 2\n",
    "            x2 = x1 + w_box\n",
    "            y2 = y1 + h_box\n",
    "            \n",
    "            # Apply Margin\n",
    "            pad_w = int(w_box * MARGIN_RATIO)\n",
    "            pad_h = int(h_box * MARGIN_RATIO)\n",
    "            crop_coords = [x1 - pad_w, y1 - pad_h, x2 + pad_w, y2 + pad_h]\n",
    "            \n",
    "            # --- APPLY SAME CROP TO ALL 3 FRAMES ---\n",
    "            crop_0 = safe_crop_with_padding(img_t0, crop_coords)\n",
    "            crop_1 = safe_crop_with_padding(img_t1, crop_coords)\n",
    "            crop_2 = safe_crop_with_padding(img_t2, crop_coords)\n",
    "            \n",
    "            # --- SAVE ---\n",
    "            cls_name = CLASS_MAP.get(cls_id, 'U')\n",
    "            obj_index = f\"{idx:02d}\"\n",
    "            \n",
    "            # Save t0 (Current)\n",
    "            name_0 = f\"{vid_id}_{frame_t}_{cls_name}_{obj_index}_t0.jpg\"\n",
    "            cv2.imwrite(os.path.join(OUTPUT_DIR, cls_name, name_0), crop_0)\n",
    "\n",
    "            # Save t1 (Previous)\n",
    "            name_1 = f\"{vid_id}_{frame_t}_{cls_name}_{obj_index}_t1.jpg\"\n",
    "            cv2.imwrite(os.path.join(OUTPUT_DIR, cls_name, name_1), crop_1)\n",
    "\n",
    "            # Save t2 (2 frames ago)\n",
    "            name_2 = f\"{vid_id}_{frame_t}_{cls_name}_{obj_index}_t2.jpg\"\n",
    "            cv2.imwrite(os.path.join(OUTPUT_DIR, cls_name, name_2), crop_2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_temporal_crops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c1c6f",
   "metadata": {},
   "source": [
    "## Converting 3-class to 2-class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cae32ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing from: /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/2_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/val\n",
      "Saving to:     /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/2_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/val/converted_2class_labels\n",
      "Found 518 files in /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/2_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting files: 100%|██████████| 518/518 [00:00<00:00, 4464.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Please check the 'converted_2class_labels' folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_3class_to_2class(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Converts YOLO annotations from 3 classes to 2 classes.\n",
    "    Mapping:\n",
    "        Original 0 -> New 0\n",
    "        Original 2 -> New 0\n",
    "        Original 1 -> New 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all txt files\n",
    "    txt_files = glob.glob(os.path.join(input_folder, \"*.txt\"))\n",
    "    print(f\"Found {len(txt_files)} files in {input_folder}\")\n",
    "    \n",
    "    for txt_file in tqdm(txt_files, desc=\"Converting files\"):\n",
    "        filename = os.path.basename(txt_file)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        new_lines = []\n",
    "        \n",
    "        with open(txt_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                continue\n",
    "                \n",
    "            # Parse original class\n",
    "            cls_id = int(parts[0])\n",
    "            coords = parts[1:] # x, y, w, h\n",
    "            \n",
    "            # --- MAPPING LOGIC ---\n",
    "            # Original 0 and 2 become 0\n",
    "            # Original 1 remains 1\n",
    "            if cls_id == 0 or cls_id == 2:\n",
    "                new_cls_id = 0\n",
    "            elif cls_id == 1:\n",
    "                new_cls_id = 1\n",
    "            else:\n",
    "                # Handle unexpected classes if necessary (e.g., skip or keep)\n",
    "                # print(f\"Warning: Unexpected class {cls_id} in {filename}\")\n",
    "                continue \n",
    "            \n",
    "            # Reconstruct the line\n",
    "            new_line = f\"{new_cls_id} {' '.join(coords)}\\n\"\n",
    "            new_lines.append(new_line)\n",
    "            \n",
    "        # Write to new file in output folder\n",
    "        with open(output_path, 'w') as f_out:\n",
    "            f_out.writelines(new_lines)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- CONFIGURATION ---\n",
    "    # The path you provided\n",
    "    input_dir = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/2_class/Euljiro_off_peak_TrainVal_balanced_2sec_plus_addition_1sec_FINAL_20260117/val\"\n",
    "    \n",
    "    # Suggested output path (creates a 'converted' folder next to the original)\n",
    "    # You can change this path if you want it somewhere else\n",
    "    output_dir = os.path.join(input_dir, \"converted_2class_labels\")\n",
    "    \n",
    "    print(f\"Processing from: {input_dir}\")\n",
    "    print(f\"Saving to:     {output_dir}\")\n",
    "    \n",
    "    convert_3class_to_2class(input_dir, output_dir)\n",
    "    print(\"Done! Please check the 'converted_2class_labels' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac0128",
   "metadata": {},
   "source": [
    "## To give perturbation to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36912d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 536 images in /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_Test\n",
      "Processing to /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_Test_Perturbed_BlackBorder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 536/536 [00:03<00:00, 174.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Perturbed dataset saved to: /media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_Test_Perturbed_BlackBorder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# Input directory\n",
    "INPUT_DIR = \"/media/holidayj/Documents/Data/Platform/final_dataset/Euljiro/0_2_Original_dataset_Euljiro_off_peak_inner_20201128_f1038_t1519/3_class/Euljiro_off_peak_Test\"\n",
    "\n",
    "# Output directory (Will be created automatically)\n",
    "OUTPUT_DIR = INPUT_DIR + \"_Perturbed_BlackBorder\"\n",
    "\n",
    "# Perturbation Parameters (Slight changes as per reviewer)\n",
    "ANGLE_LIMIT = 3       # +/- 5 degrees\n",
    "SHIFT_LIMIT = 0.03    # +/- 5% shift\n",
    "SCALE_LIMIT = 0.03    # +/- 5% scale (0.95 - 1.05)\n",
    "BRIGHTNESS_LIMIT = 5 # +/- 10 pixel values\n",
    "# =================================================\n",
    "\n",
    "def yolo_to_corners(yolo_line, img_w, img_h):\n",
    "    \"\"\"Convert single YOLO line to [xmin, ymin, xmax, ymax]\"\"\"\n",
    "    parts = list(map(float, yolo_line.split()))\n",
    "    cls_id = int(parts[0])\n",
    "    cx, cy, w, h = parts[1], parts[2], parts[3], parts[4]\n",
    "    \n",
    "    x_min = int((cx - w/2) * img_w)\n",
    "    y_min = int((cy - h/2) * img_h)\n",
    "    x_max = int((cx + w/2) * img_w)\n",
    "    y_max = int((cy + h/2) * img_h)\n",
    "    \n",
    "    return cls_id, [x_min, y_min, x_max, y_max]\n",
    "\n",
    "def corners_to_yolo(box, img_w, img_h):\n",
    "    \"\"\"Convert [xmin, ymin, xmax, ymax] back to YOLO [cx, cy, w, h] normalized\"\"\"\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    \n",
    "    # Clip to image boundaries\n",
    "    xmin = max(0, xmin); ymin = max(0, ymin)\n",
    "    xmax = min(img_w, xmax); ymax = min(img_h, ymax)\n",
    "    \n",
    "    # Calculate width/height\n",
    "    box_w = xmax - xmin\n",
    "    box_h = ymax - ymin\n",
    "    \n",
    "    # Avoid zero-area boxes\n",
    "    if box_w <= 1 or box_h <= 1:\n",
    "        return None\n",
    "        \n",
    "    cx = (xmin + box_w/2.0) / img_w\n",
    "    cy = (ymin + box_h/2.0) / img_h\n",
    "    nw = box_w / float(img_w)\n",
    "    nh = box_h / float(img_h)\n",
    "    \n",
    "    return [cx, cy, nw, nh]\n",
    "\n",
    "def apply_perturbation(image, boxes, angle_lim, shift_lim, scale_lim, bright_lim):\n",
    "    h, w = image.shape[:2]\n",
    "    cx, cy = w // 2, h // 2\n",
    "\n",
    "    # 1. Random Parameters\n",
    "    angle = random.uniform(-angle_lim, angle_lim)\n",
    "    tx = random.uniform(-shift_lim, shift_lim) * w\n",
    "    ty = random.uniform(-shift_lim, shift_lim) * h\n",
    "    scale = random.uniform(1 - scale_lim, 1 + scale_lim)\n",
    "    beta = random.uniform(-bright_lim, bright_lim) \n",
    "\n",
    "    # 2. Geometric Transform (Rotation + Scale + Translation)\n",
    "    M = cv2.getRotationMatrix2D((cx, cy), angle, scale)\n",
    "    M[0, 2] += tx\n",
    "    M[1, 2] += ty\n",
    "\n",
    "    # === UPDATED SECTION: Black Borders ===\n",
    "    # borderMode=cv2.BORDER_CONSTANT fills outer area with a solid color\n",
    "    # borderValue=(0, 0, 0) specifies that color is black\n",
    "    aug_image = cv2.warpAffine(\n",
    "        image, M, (w, h), \n",
    "        borderMode=cv2.BORDER_CONSTANT, \n",
    "        borderValue=(0, 0, 0)\n",
    "    )\n",
    "    # ======================================\n",
    "    \n",
    "    # Apply Brightness\n",
    "    aug_image = cv2.convertScaleAbs(aug_image, alpha=1.0, beta=beta)\n",
    "\n",
    "    # 3. Transform Boxes\n",
    "    aug_boxes = [] \n",
    "    \n",
    "    for cls_id, box in boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        \n",
    "        corners = np.array([\n",
    "            [x_min, y_min], [x_max, y_min],\n",
    "            [x_max, y_max], [x_min, y_max]\n",
    "        ])\n",
    "        ones = np.ones((4, 1))\n",
    "        corners_ones = np.hstack([corners, ones])\n",
    "        \n",
    "        # Transform corners\n",
    "        tf_corners = M.dot(corners_ones.T).T\n",
    "        \n",
    "        # New axis-aligned box\n",
    "        new_xmin = np.min(tf_corners[:, 0])\n",
    "        new_ymin = np.min(tf_corners[:, 1])\n",
    "        new_xmax = np.max(tf_corners[:, 0])\n",
    "        new_ymax = np.max(tf_corners[:, 1])\n",
    "        \n",
    "        # Convert back to YOLO\n",
    "        yolo_box = corners_to_yolo([new_xmin, new_ymin, new_xmax, new_ymax], w, h)\n",
    "        \n",
    "        if yolo_box is not None:\n",
    "            aug_boxes.append((cls_id, yolo_box))\n",
    "            \n",
    "    return aug_image, aug_boxes\n",
    "\n",
    "def main():\n",
    "    # Setup Paths\n",
    "    input_path = Path(INPUT_DIR)\n",
    "    output_path = Path(OUTPUT_DIR)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all images\n",
    "    img_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "    img_files = []\n",
    "    for ext in img_extensions:\n",
    "        img_files.extend(list(input_path.glob(ext)))\n",
    "    \n",
    "    print(f\"Found {len(img_files)} images in {INPUT_DIR}\")\n",
    "    print(f\"Processing to {OUTPUT_DIR}...\")\n",
    "\n",
    "    for img_file in tqdm(img_files):\n",
    "        # 1. Read Image\n",
    "        img = cv2.imread(str(img_file))\n",
    "        if img is None: continue\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # 2. Read Label\n",
    "        label_file = img_file.with_suffix('.txt')\n",
    "        boxes = [] \n",
    "        \n",
    "        if label_file.exists():\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip():\n",
    "                        cls_id, pixel_box = yolo_to_corners(line, w, h)\n",
    "                        boxes.append((cls_id, pixel_box))\n",
    "        \n",
    "        # 3. Apply Perturbation\n",
    "        aug_img, aug_yolo_data = apply_perturbation(\n",
    "            img, boxes, ANGLE_LIMIT, SHIFT_LIMIT, SCALE_LIMIT, BRIGHTNESS_LIMIT\n",
    "        )\n",
    "        \n",
    "        # 4. Save Image\n",
    "        out_img_path = output_path / img_file.name\n",
    "        cv2.imwrite(str(out_img_path), aug_img)\n",
    "        \n",
    "        # 5. Save Label\n",
    "        out_lbl_path = output_path / label_file.name\n",
    "        with open(out_lbl_path, 'w') as f:\n",
    "            for cls_id, (cx, cy, nw, nh) in aug_yolo_data:\n",
    "                f.write(f\"{cls_id} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\\n\")\n",
    "\n",
    "    print(f\"\\nDone! Perturbed dataset saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
